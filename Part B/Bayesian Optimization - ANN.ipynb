{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67787968",
   "metadata": {},
   "source": [
    "# Bayesian Optimization - ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fda7f99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# original result --> 60.7700%\n",
    "from functions import ann\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from bayes_opt import BayesianOptimization\n",
    "import numpy as np\n",
    "from functions import load_data\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPool2D, Flatten, Dropout, BatchNormalization\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "(x_train, x_test, y_train, y_test) = load_data(data_train=\"../Data/train_hog.csv\", data_test=\"../Data/test_hog.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80a6888e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ann = ann((324, ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b225aae4",
   "metadata": {},
   "source": [
    "# Original ANN Layer Objective Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7632ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the objective function\n",
    "def objective_function(units1, units2, units3, units4, learning_rate):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=int(units1), activation='relu', input_shape=(324,)))\n",
    "    model.add(Dense(units=int(units2), activation='relu'))\n",
    "    model.add(Dense(units=int(units3), activation='relu'))\n",
    "    model.add(Dense(units=int(units4), activation='relu'))\n",
    "    model.add(Dense(units=10, activation='softmax'))\n",
    "\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    # Define the early stopping callback\n",
    "    early_stop = EarlyStopping(monitor='val_loss', patience=5, verbose=0, restore_best_weights=True)\n",
    "    \n",
    "    history = model.fit(x_train, y_train, verbose=0, validation_data=(x_test, y_test), callbacks=[early_stop])\n",
    "\n",
    "    val_acc = history.history['val_accuracy'][-1]\n",
    "    return val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0a24d9c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | learni... |  units1   |  units2   |  units3   |  units4   |\n",
      "-------------------------------------------------------------------------------------\n",
      "| \u001b[0m1        \u001b[0m | \u001b[0m0.5301   \u001b[0m | \u001b[0m0.001116 \u001b[0m | \u001b[0m511.1    \u001b[0m | \u001b[0m106.6    \u001b[0m | \u001b[0m386.6    \u001b[0m | \u001b[0m263.7    \u001b[0m |\n",
      "| \u001b[0m2        \u001b[0m | \u001b[0m0.4874   \u001b[0m | \u001b[0m0.005861 \u001b[0m | \u001b[0m226.5    \u001b[0m | \u001b[0m276.6    \u001b[0m | \u001b[0m38.45    \u001b[0m | \u001b[0m47.41    \u001b[0m |\n",
      "| \u001b[0m3        \u001b[0m | \u001b[0m0.4364   \u001b[0m | \u001b[0m0.007119 \u001b[0m | \u001b[0m226.1    \u001b[0m | \u001b[0m280.4    \u001b[0m | \u001b[0m361.7    \u001b[0m | \u001b[0m128.2    \u001b[0m |\n",
      "| \u001b[0m4        \u001b[0m | \u001b[0m0.4869   \u001b[0m | \u001b[0m0.00577  \u001b[0m | \u001b[0m88.81    \u001b[0m | \u001b[0m290.6    \u001b[0m | \u001b[0m158.0    \u001b[0m | \u001b[0m489.5    \u001b[0m |\n",
      "| \u001b[0m5        \u001b[0m | \u001b[0m0.4675   \u001b[0m | \u001b[0m0.005801 \u001b[0m | \u001b[0m106.0    \u001b[0m | \u001b[0m379.0    \u001b[0m | \u001b[0m327.6    \u001b[0m | \u001b[0m87.03    \u001b[0m |\n",
      "| \u001b[0m6        \u001b[0m | \u001b[0m0.4404   \u001b[0m | \u001b[0m0.009559 \u001b[0m | \u001b[0m197.7    \u001b[0m | \u001b[0m419.4    \u001b[0m | \u001b[0m471.2    \u001b[0m | \u001b[0m133.3    \u001b[0m |\n",
      "| \u001b[0m7        \u001b[0m | \u001b[0m0.418    \u001b[0m | \u001b[0m0.009501 \u001b[0m | \u001b[0m94.71    \u001b[0m | \u001b[0m381.9    \u001b[0m | \u001b[0m353.0    \u001b[0m | \u001b[0m187.6    \u001b[0m |\n",
      "| \u001b[0m8        \u001b[0m | \u001b[0m0.4454   \u001b[0m | \u001b[0m0.009541 \u001b[0m | \u001b[0m397.6    \u001b[0m | \u001b[0m303.9    \u001b[0m | \u001b[0m128.7    \u001b[0m | \u001b[0m508.1    \u001b[0m |\n",
      "| \u001b[95m9        \u001b[0m | \u001b[95m0.532    \u001b[0m | \u001b[95m0.0003937\u001b[0m | \u001b[95m200.7    \u001b[0m | \u001b[95m128.7    \u001b[0m | \u001b[95m108.9    \u001b[0m | \u001b[95m364.7    \u001b[0m |\n",
      "| \u001b[0m10       \u001b[0m | \u001b[0m0.4576   \u001b[0m | \u001b[0m0.007021 \u001b[0m | \u001b[0m103.0    \u001b[0m | \u001b[0m94.14    \u001b[0m | \u001b[0m61.55    \u001b[0m | \u001b[0m466.6    \u001b[0m |\n",
      "| \u001b[0m11       \u001b[0m | \u001b[0m0.4696   \u001b[0m | \u001b[0m0.0001   \u001b[0m | \u001b[0m216.4    \u001b[0m | \u001b[0m147.7    \u001b[0m | \u001b[0m145.4    \u001b[0m | \u001b[0m307.6    \u001b[0m |\n",
      "| \u001b[0m12       \u001b[0m | \u001b[0m0.5023   \u001b[0m | \u001b[0m0.001731 \u001b[0m | \u001b[0m414.2    \u001b[0m | \u001b[0m283.5    \u001b[0m | \u001b[0m500.5    \u001b[0m | \u001b[0m460.6    \u001b[0m |\n",
      "| \u001b[0m13       \u001b[0m | \u001b[0m0.5096   \u001b[0m | \u001b[0m0.003574 \u001b[0m | \u001b[0m107.1    \u001b[0m | \u001b[0m387.9    \u001b[0m | \u001b[0m57.56    \u001b[0m | \u001b[0m107.6    \u001b[0m |\n",
      "| \u001b[0m14       \u001b[0m | \u001b[0m0.4413   \u001b[0m | \u001b[0m0.008214 \u001b[0m | \u001b[0m46.93    \u001b[0m | \u001b[0m92.12    \u001b[0m | \u001b[0m297.7    \u001b[0m | \u001b[0m122.2    \u001b[0m |\n",
      "| \u001b[0m15       \u001b[0m | \u001b[0m0.5212   \u001b[0m | \u001b[0m0.002825 \u001b[0m | \u001b[0m421.7    \u001b[0m | \u001b[0m174.4    \u001b[0m | \u001b[0m68.01    \u001b[0m | \u001b[0m296.1    \u001b[0m |\n",
      "| \u001b[0m16       \u001b[0m | \u001b[0m0.4486   \u001b[0m | \u001b[0m0.00707  \u001b[0m | \u001b[0m76.57    \u001b[0m | \u001b[0m289.0    \u001b[0m | \u001b[0m151.8    \u001b[0m | \u001b[0m491.8    \u001b[0m |\n",
      "| \u001b[0m17       \u001b[0m | \u001b[0m0.4993   \u001b[0m | \u001b[0m0.004018 \u001b[0m | \u001b[0m346.5    \u001b[0m | \u001b[0m273.2    \u001b[0m | \u001b[0m453.4    \u001b[0m | \u001b[0m216.8    \u001b[0m |\n",
      "| \u001b[0m18       \u001b[0m | \u001b[0m0.4827   \u001b[0m | \u001b[0m0.004222 \u001b[0m | \u001b[0m115.1    \u001b[0m | \u001b[0m227.2    \u001b[0m | \u001b[0m435.6    \u001b[0m | \u001b[0m188.8    \u001b[0m |\n",
      "| \u001b[0m19       \u001b[0m | \u001b[0m0.4503   \u001b[0m | \u001b[0m0.007318 \u001b[0m | \u001b[0m213.9    \u001b[0m | \u001b[0m183.0    \u001b[0m | \u001b[0m344.0    \u001b[0m | \u001b[0m439.1    \u001b[0m |\n",
      "| \u001b[0m20       \u001b[0m | \u001b[0m0.4974   \u001b[0m | \u001b[0m0.001054 \u001b[0m | \u001b[0m42.89    \u001b[0m | \u001b[0m439.8    \u001b[0m | \u001b[0m350.2    \u001b[0m | \u001b[0m316.8    \u001b[0m |\n",
      "=====================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Define the search space\n",
    "pbounds = {'units1': (32, 512),\n",
    "           'units2': (32, 512),\n",
    "           'units3': (32, 512),\n",
    "           'units4': (32, 512),\n",
    "           'learning_rate': (1e-4, 1e-2)}\n",
    "\n",
    "# Run the optimization\n",
    "optimizer2 = BayesianOptimization(f=objective_function, pbounds=pbounds)\n",
    "optimizer2.maximize(init_points=10, n_iter=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ecc70521",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | learni... |  units1   |  units2   |  units3   |  units4   |\n",
      "-------------------------------------------------------------------------------------\n",
      "| \u001b[0m1        \u001b[0m | \u001b[0m0.5006   \u001b[0m | \u001b[0m0.003808 \u001b[0m | \u001b[0m487.6    \u001b[0m | \u001b[0m223.9    \u001b[0m | \u001b[0m83.05    \u001b[0m | \u001b[0m33.47    \u001b[0m |\n",
      "| \u001b[0m2        \u001b[0m | \u001b[0m0.4981   \u001b[0m | \u001b[0m0.001644 \u001b[0m | \u001b[0m44.81    \u001b[0m | \u001b[0m262.0    \u001b[0m | \u001b[0m83.32    \u001b[0m | \u001b[0m95.3     \u001b[0m |\n",
      "| \u001b[95m3        \u001b[0m | \u001b[95m0.5102   \u001b[0m | \u001b[95m0.0003038\u001b[0m | \u001b[95m497.1    \u001b[0m | \u001b[95m252.4    \u001b[0m | \u001b[95m39.78    \u001b[0m | \u001b[95m36.36    \u001b[0m |\n",
      "| \u001b[95m4        \u001b[0m | \u001b[95m0.5183   \u001b[0m | \u001b[95m0.001916 \u001b[0m | \u001b[95m166.9    \u001b[0m | \u001b[95m165.0    \u001b[0m | \u001b[95m64.38    \u001b[0m | \u001b[95m48.62    \u001b[0m |\n",
      "| \u001b[0m5        \u001b[0m | \u001b[0m0.4731   \u001b[0m | \u001b[0m0.006157 \u001b[0m | \u001b[0m85.19    \u001b[0m | \u001b[0m98.97    \u001b[0m | \u001b[0m57.03    \u001b[0m | \u001b[0m67.08    \u001b[0m |\n",
      "| \u001b[0m6        \u001b[0m | \u001b[0m0.4509   \u001b[0m | \u001b[0m0.007873 \u001b[0m | \u001b[0m115.0    \u001b[0m | \u001b[0m162.0    \u001b[0m | \u001b[0m82.35    \u001b[0m | \u001b[0m21.2     \u001b[0m |\n",
      "| \u001b[0m7        \u001b[0m | \u001b[0m0.4642   \u001b[0m | \u001b[0m0.006115 \u001b[0m | \u001b[0m100.6    \u001b[0m | \u001b[0m34.47    \u001b[0m | \u001b[0m122.3    \u001b[0m | \u001b[0m124.2    \u001b[0m |\n",
      "| \u001b[0m8        \u001b[0m | \u001b[0m0.485    \u001b[0m | \u001b[0m0.008103 \u001b[0m | \u001b[0m167.1    \u001b[0m | \u001b[0m43.74    \u001b[0m | \u001b[0m92.63    \u001b[0m | \u001b[0m65.3     \u001b[0m |\n",
      "| \u001b[0m9        \u001b[0m | \u001b[0m0.5045   \u001b[0m | \u001b[0m0.001308 \u001b[0m | \u001b[0m261.6    \u001b[0m | \u001b[0m25.77    \u001b[0m | \u001b[0m117.8    \u001b[0m | \u001b[0m44.98    \u001b[0m |\n",
      "| \u001b[0m10       \u001b[0m | \u001b[0m0.4873   \u001b[0m | \u001b[0m0.006659 \u001b[0m | \u001b[0m170.6    \u001b[0m | \u001b[0m163.7    \u001b[0m | \u001b[0m77.23    \u001b[0m | \u001b[0m36.7     \u001b[0m |\n",
      "| \u001b[0m11       \u001b[0m | \u001b[0m0.5109   \u001b[0m | \u001b[0m0.003932 \u001b[0m | \u001b[0m358.8    \u001b[0m | \u001b[0m89.28    \u001b[0m | \u001b[0m109.2    \u001b[0m | \u001b[0m84.3     \u001b[0m |\n",
      "| \u001b[0m12       \u001b[0m | \u001b[0m0.3975   \u001b[0m | \u001b[0m0.009073 \u001b[0m | \u001b[0m68.26    \u001b[0m | \u001b[0m57.83    \u001b[0m | \u001b[0m119.6    \u001b[0m | \u001b[0m102.3    \u001b[0m |\n",
      "| \u001b[0m13       \u001b[0m | \u001b[0m0.4771   \u001b[0m | \u001b[0m0.008688 \u001b[0m | \u001b[0m363.8    \u001b[0m | \u001b[0m91.34    \u001b[0m | \u001b[0m101.5    \u001b[0m | \u001b[0m80.54    \u001b[0m |\n",
      "| \u001b[0m14       \u001b[0m | \u001b[0m0.5141   \u001b[0m | \u001b[0m0.004739 \u001b[0m | \u001b[0m508.5    \u001b[0m | \u001b[0m277.8    \u001b[0m | \u001b[0m64.36    \u001b[0m | \u001b[0m51.34    \u001b[0m |\n",
      "| \u001b[0m15       \u001b[0m | \u001b[0m0.4684   \u001b[0m | \u001b[0m0.006195 \u001b[0m | \u001b[0m166.4    \u001b[0m | \u001b[0m156.8    \u001b[0m | \u001b[0m66.75    \u001b[0m | \u001b[0m52.18    \u001b[0m |\n",
      "| \u001b[0m16       \u001b[0m | \u001b[0m0.4994   \u001b[0m | \u001b[0m0.004964 \u001b[0m | \u001b[0m142.8    \u001b[0m | \u001b[0m224.8    \u001b[0m | \u001b[0m82.73    \u001b[0m | \u001b[0m105.4    \u001b[0m |\n",
      "| \u001b[95m17       \u001b[0m | \u001b[95m0.5466   \u001b[0m | \u001b[95m0.0008471\u001b[0m | \u001b[95m418.7    \u001b[0m | \u001b[95m148.5    \u001b[0m | \u001b[95m50.25    \u001b[0m | \u001b[95m49.46    \u001b[0m |\n",
      "| \u001b[0m18       \u001b[0m | \u001b[0m0.5417   \u001b[0m | \u001b[0m0.0009168\u001b[0m | \u001b[0m464.3    \u001b[0m | \u001b[0m184.6    \u001b[0m | \u001b[0m99.97    \u001b[0m | \u001b[0m99.79    \u001b[0m |\n",
      "| \u001b[0m19       \u001b[0m | \u001b[0m0.4642   \u001b[0m | \u001b[0m0.007309 \u001b[0m | \u001b[0m347.1    \u001b[0m | \u001b[0m298.4    \u001b[0m | \u001b[0m61.54    \u001b[0m | \u001b[0m76.34    \u001b[0m |\n",
      "| \u001b[0m20       \u001b[0m | \u001b[0m0.5358   \u001b[0m | \u001b[0m0.001423 \u001b[0m | \u001b[0m381.7    \u001b[0m | \u001b[0m101.6    \u001b[0m | \u001b[0m37.23    \u001b[0m | \u001b[0m41.41    \u001b[0m |\n",
      "| \u001b[0m21       \u001b[0m | \u001b[0m0.5206   \u001b[0m | \u001b[0m0.002787 \u001b[0m | \u001b[0m339.2    \u001b[0m | \u001b[0m33.66    \u001b[0m | \u001b[0m99.68    \u001b[0m | \u001b[0m123.4    \u001b[0m |\n",
      "| \u001b[0m22       \u001b[0m | \u001b[0m0.4801   \u001b[0m | \u001b[0m0.001722 \u001b[0m | \u001b[0m66.14    \u001b[0m | \u001b[0m83.57    \u001b[0m | \u001b[0m118.2    \u001b[0m | \u001b[0m105.1    \u001b[0m |\n",
      "| \u001b[0m23       \u001b[0m | \u001b[0m0.459    \u001b[0m | \u001b[0m0.007797 \u001b[0m | \u001b[0m193.3    \u001b[0m | \u001b[0m253.9    \u001b[0m | \u001b[0m120.7    \u001b[0m | \u001b[0m34.26    \u001b[0m |\n",
      "| \u001b[0m24       \u001b[0m | \u001b[0m0.4872   \u001b[0m | \u001b[0m0.005106 \u001b[0m | \u001b[0m269.8    \u001b[0m | \u001b[0m240.8    \u001b[0m | \u001b[0m53.01    \u001b[0m | \u001b[0m119.3    \u001b[0m |\n",
      "| \u001b[0m25       \u001b[0m | \u001b[0m0.4842   \u001b[0m | \u001b[0m0.008652 \u001b[0m | \u001b[0m299.8    \u001b[0m | \u001b[0m134.2    \u001b[0m | \u001b[0m36.52    \u001b[0m | \u001b[0m47.52    \u001b[0m |\n",
      "| \u001b[0m26       \u001b[0m | \u001b[0m0.499    \u001b[0m | \u001b[0m0.006286 \u001b[0m | \u001b[0m394.5    \u001b[0m | \u001b[0m124.9    \u001b[0m | \u001b[0m37.27    \u001b[0m | \u001b[0m109.8    \u001b[0m |\n",
      "| \u001b[0m27       \u001b[0m | \u001b[0m0.46     \u001b[0m | \u001b[0m0.005705 \u001b[0m | \u001b[0m41.87    \u001b[0m | \u001b[0m119.4    \u001b[0m | \u001b[0m34.28    \u001b[0m | \u001b[0m33.35    \u001b[0m |\n",
      "| \u001b[0m28       \u001b[0m | \u001b[0m0.5038   \u001b[0m | \u001b[0m0.005407 \u001b[0m | \u001b[0m413.6    \u001b[0m | \u001b[0m250.6    \u001b[0m | \u001b[0m77.53    \u001b[0m | \u001b[0m77.18    \u001b[0m |\n",
      "| \u001b[0m29       \u001b[0m | \u001b[0m0.4774   \u001b[0m | \u001b[0m0.0007795\u001b[0m | \u001b[0m50.34    \u001b[0m | \u001b[0m59.53    \u001b[0m | \u001b[0m53.88    \u001b[0m | \u001b[0m57.8     \u001b[0m |\n",
      "| \u001b[0m30       \u001b[0m | \u001b[0m0.5098   \u001b[0m | \u001b[0m0.004421 \u001b[0m | \u001b[0m90.94    \u001b[0m | \u001b[0m180.2    \u001b[0m | \u001b[0m97.18    \u001b[0m | \u001b[0m31.22    \u001b[0m |\n",
      "=====================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Define the search space\n",
    "pbounds = {'units1': (16, 512),\n",
    "           'units2': (16, 300),\n",
    "           'units3': (16, 128),\n",
    "           'units4': (16, 128),\n",
    "           'learning_rate': (1e-4, 1e-2)\n",
    "          }\n",
    "# Run the optimization\n",
    "optimizer2 = BayesianOptimization(f=objective_function, pbounds=pbounds, random_state=42)\n",
    "optimizer2.maximize(init_points=10, n_iter=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c580dc6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the objective function\n",
    "def objective_function(units1, units2, units3, units4, learning_rate, batch_size, n_epochs):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=int(units1), activation='relu', input_shape=(324,)))\n",
    "    model.add(Dense(units=int(units2), activation='relu'))\n",
    "    model.add(Dense(units=int(units3), activation='relu'))\n",
    "    model.add(Dense(units=int(units4), activation='relu'))\n",
    "    model.add(Dense(units=10, activation='softmax'))\n",
    "\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    # Define the early stopping callback\n",
    "    early_stop = EarlyStopping(monitor='val_loss', patience=5, verbose=0, restore_best_weights=True)\n",
    "    \n",
    "    history = model.fit(x_train, y_train, batch_size=int(batch_size), epochs=int(n_epochs), verbose=0, validation_data=(x_test, y_test), callbacks=[early_stop])\n",
    "\n",
    "    val_acc = history.history['val_accuracy'][-1]\n",
    "    return val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "27292b4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | batch_... | learni... | n_epochs  |  units1   |  units2   |  units3   |  units4   |\n",
      "-------------------------------------------------------------------------------------------------------------\n",
      "| \u001b[0m1        \u001b[0m | \u001b[0m0.5974   \u001b[0m | \u001b[0m187.4    \u001b[0m | \u001b[0m0.009512 \u001b[0m | \u001b[0m39.28    \u001b[0m | \u001b[0m312.9    \u001b[0m | \u001b[0m60.31    \u001b[0m | \u001b[0m33.47    \u001b[0m | \u001b[0m22.51    \u001b[0m |\n",
      "| \u001b[0m2        \u001b[0m | \u001b[0m0.5795   \u001b[0m | \u001b[0m275.9    \u001b[0m | \u001b[0m0.006051 \u001b[0m | \u001b[0m38.32    \u001b[0m | \u001b[0m26.21    \u001b[0m | \u001b[0m291.5    \u001b[0m | \u001b[0m109.2    \u001b[0m | \u001b[0m39.78    \u001b[0m |\n",
      "| \u001b[95m3        \u001b[0m | \u001b[95m0.6182   \u001b[0m | \u001b[95m152.7    \u001b[0m | \u001b[95m0.001916 \u001b[0m | \u001b[95m22.17    \u001b[0m | \u001b[95m276.3    \u001b[0m | \u001b[95m138.7    \u001b[0m | \u001b[95m48.62    \u001b[0m | \u001b[95m84.53    \u001b[0m |\n",
      "| \u001b[0m4        \u001b[0m | \u001b[0m0.6109   \u001b[0m | \u001b[0m145.1    \u001b[0m | \u001b[0m0.002992 \u001b[0m | \u001b[0m24.65    \u001b[0m | \u001b[0m242.2    \u001b[0m | \u001b[0m239.0    \u001b[0m | \u001b[0m38.36    \u001b[0m | \u001b[0m73.59    \u001b[0m |\n",
      "| \u001b[0m5        \u001b[0m | \u001b[0m0.601    \u001b[0m | \u001b[0m226.6    \u001b[0m | \u001b[0m0.0005599\u001b[0m | \u001b[0m34.3     \u001b[0m | \u001b[0m100.6    \u001b[0m | \u001b[0m34.47    \u001b[0m | \u001b[0m122.3    \u001b[0m | \u001b[0m124.2    \u001b[0m |\n",
      "| \u001b[0m6        \u001b[0m | \u001b[0m0.6154   \u001b[0m | \u001b[0m265.5    \u001b[0m | \u001b[0m0.003116 \u001b[0m | \u001b[0m13.91    \u001b[0m | \u001b[0m355.4    \u001b[0m | \u001b[0m141.0    \u001b[0m | \u001b[0m29.67    \u001b[0m | \u001b[0m71.46    \u001b[0m |\n",
      "| \u001b[0m7        \u001b[0m | \u001b[0m0.5956   \u001b[0m | \u001b[0m126.2    \u001b[0m | \u001b[0m0.009102 \u001b[0m | \u001b[0m20.35    \u001b[0m | \u001b[0m344.6    \u001b[0m | \u001b[0m104.5    \u001b[0m | \u001b[0m74.25    \u001b[0m | \u001b[0m77.23    \u001b[0m |\n",
      "| \u001b[0m8        \u001b[0m | \u001b[0m0.5875   \u001b[0m | \u001b[0m153.3    \u001b[0m | \u001b[0m0.009699 \u001b[0m | \u001b[0m41.01    \u001b[0m | \u001b[0m482.0    \u001b[0m | \u001b[0m270.1    \u001b[0m | \u001b[0m82.96    \u001b[0m | \u001b[0m119.2    \u001b[0m |\n",
      "| \u001b[0m9        \u001b[0m | \u001b[0m0.617    \u001b[0m | \u001b[0m135.9    \u001b[0m | \u001b[0m0.00204  \u001b[0m | \u001b[0m11.81    \u001b[0m | \u001b[0m177.4    \u001b[0m | \u001b[0m126.4    \u001b[0m | \u001b[0m46.39    \u001b[0m | \u001b[0m108.8    \u001b[0m |\n",
      "| \u001b[0m10       \u001b[0m | \u001b[0m0.6132   \u001b[0m | \u001b[0m184.2    \u001b[0m | \u001b[0m0.002881 \u001b[0m | \u001b[0m31.71    \u001b[0m | \u001b[0m85.9     \u001b[0m | \u001b[0m243.8    \u001b[0m | \u001b[0m24.35    \u001b[0m | \u001b[0m126.5    \u001b[0m |\n",
      "| \u001b[0m11       \u001b[0m | \u001b[0m0.615    \u001b[0m | \u001b[0m136.8    \u001b[0m | \u001b[0m0.004008 \u001b[0m | \u001b[0m29.12    \u001b[0m | \u001b[0m349.4    \u001b[0m | \u001b[0m201.7    \u001b[0m | \u001b[0m117.5    \u001b[0m | \u001b[0m109.9    \u001b[0m |\n",
      "| \u001b[95m12       \u001b[0m | \u001b[95m0.6225   \u001b[0m | \u001b[95m131.6    \u001b[0m | \u001b[95m0.001179 \u001b[0m | \u001b[95m45.86    \u001b[0m | \u001b[95m437.6    \u001b[0m | \u001b[95m229.5    \u001b[0m | \u001b[95m47.24    \u001b[0m | \u001b[95m71.76    \u001b[0m |\n",
      "| \u001b[0m13       \u001b[0m | \u001b[0m0.6042   \u001b[0m | \u001b[0m196.6    \u001b[0m | \u001b[0m0.003474 \u001b[0m | \u001b[0m46.2     \u001b[0m | \u001b[0m250.4    \u001b[0m | \u001b[0m283.7    \u001b[0m | \u001b[0m49.29    \u001b[0m | \u001b[0m92.21    \u001b[0m |\n",
      "| \u001b[95m14       \u001b[0m | \u001b[95m0.6307   \u001b[0m | \u001b[95m299.7    \u001b[0m | \u001b[95m0.0006065\u001b[0m | \u001b[95m41.3     \u001b[0m | \u001b[95m384.2    \u001b[0m | \u001b[95m241.0    \u001b[0m | \u001b[95m55.12    \u001b[0m | \u001b[95m68.01    \u001b[0m |\n",
      "| \u001b[0m15       \u001b[0m | \u001b[0m0.6111   \u001b[0m | \u001b[0m140.0    \u001b[0m | \u001b[0m0.003515 \u001b[0m | \u001b[0m13.54    \u001b[0m | \u001b[0m172.0    \u001b[0m | \u001b[0m140.3    \u001b[0m | \u001b[0m40.39    \u001b[0m | \u001b[0m111.9    \u001b[0m |\n",
      "| \u001b[0m16       \u001b[0m | \u001b[0m0.6293   \u001b[0m | \u001b[0m265.6    \u001b[0m | \u001b[0m0.002008 \u001b[0m | \u001b[0m44.03    \u001b[0m | \u001b[0m338.9    \u001b[0m | \u001b[0m204.3    \u001b[0m | \u001b[0m21.73    \u001b[0m | \u001b[0m62.9     \u001b[0m |\n",
      "| \u001b[0m17       \u001b[0m | \u001b[0m0.6208   \u001b[0m | \u001b[0m141.7    \u001b[0m | \u001b[0m0.0004432\u001b[0m | \u001b[0m25.65    \u001b[0m | \u001b[0m275.6    \u001b[0m | \u001b[0m146.9    \u001b[0m | \u001b[0m51.91    \u001b[0m | \u001b[0m86.68    \u001b[0m |\n",
      "| \u001b[0m18       \u001b[0m | \u001b[0m0.6121   \u001b[0m | \u001b[0m243.6    \u001b[0m | \u001b[0m0.0001   \u001b[0m | \u001b[0m48.75    \u001b[0m | \u001b[0m390.8    \u001b[0m | \u001b[0m228.3    \u001b[0m | \u001b[0m36.25    \u001b[0m | \u001b[0m55.15    \u001b[0m |\n",
      "| \u001b[0m19       \u001b[0m | \u001b[0m0.6256   \u001b[0m | \u001b[0m130.0    \u001b[0m | \u001b[0m0.0006787\u001b[0m | \u001b[0m29.01    \u001b[0m | \u001b[0m340.7    \u001b[0m | \u001b[0m205.1    \u001b[0m | \u001b[0m110.1    \u001b[0m | \u001b[0m104.3    \u001b[0m |\n",
      "| \u001b[0m20       \u001b[0m | \u001b[0m0.6065   \u001b[0m | \u001b[0m285.0    \u001b[0m | \u001b[0m0.005166 \u001b[0m | \u001b[0m41.63    \u001b[0m | \u001b[0m358.7    \u001b[0m | \u001b[0m222.3    \u001b[0m | \u001b[0m67.08    \u001b[0m | \u001b[0m68.37    \u001b[0m |\n",
      "| \u001b[0m21       \u001b[0m | \u001b[0m0.6051   \u001b[0m | \u001b[0m250.2    \u001b[0m | \u001b[0m0.009929 \u001b[0m | \u001b[0m48.12    \u001b[0m | \u001b[0m350.1    \u001b[0m | \u001b[0m201.4    \u001b[0m | \u001b[0m19.09    \u001b[0m | \u001b[0m47.57    \u001b[0m |\n",
      "| \u001b[0m22       \u001b[0m | \u001b[0m0.5532   \u001b[0m | \u001b[0m260.0    \u001b[0m | \u001b[0m0.007172 \u001b[0m | \u001b[0m33.94    \u001b[0m | \u001b[0m28.9     \u001b[0m | \u001b[0m141.6    \u001b[0m | \u001b[0m79.77    \u001b[0m | \u001b[0m91.68    \u001b[0m |\n",
      "| \u001b[0m23       \u001b[0m | \u001b[0m0.6068   \u001b[0m | \u001b[0m275.2    \u001b[0m | \u001b[0m0.006941 \u001b[0m | \u001b[0m38.34    \u001b[0m | \u001b[0m356.0    \u001b[0m | \u001b[0m190.0    \u001b[0m | \u001b[0m19.78    \u001b[0m | \u001b[0m78.29    \u001b[0m |\n",
      "| \u001b[0m24       \u001b[0m | \u001b[0m0.6105   \u001b[0m | \u001b[0m298.1    \u001b[0m | \u001b[0m0.008335 \u001b[0m | \u001b[0m19.32    \u001b[0m | \u001b[0m370.8    \u001b[0m | \u001b[0m237.3    \u001b[0m | \u001b[0m36.91    \u001b[0m | \u001b[0m69.69    \u001b[0m |\n",
      "| \u001b[0m25       \u001b[0m | \u001b[0m0.5813   \u001b[0m | \u001b[0m270.2    \u001b[0m | \u001b[0m0.01     \u001b[0m | \u001b[0m43.01    \u001b[0m | \u001b[0m318.5    \u001b[0m | \u001b[0m215.3    \u001b[0m | \u001b[0m22.7     \u001b[0m | \u001b[0m67.76    \u001b[0m |\n",
      "| \u001b[0m26       \u001b[0m | \u001b[0m0.5913   \u001b[0m | \u001b[0m153.6    \u001b[0m | \u001b[0m0.006949 \u001b[0m | \u001b[0m26.21    \u001b[0m | \u001b[0m233.3    \u001b[0m | \u001b[0m250.3    \u001b[0m | \u001b[0m48.65    \u001b[0m | \u001b[0m76.93    \u001b[0m |\n",
      "| \u001b[0m27       \u001b[0m | \u001b[0m0.6152   \u001b[0m | \u001b[0m146.1    \u001b[0m | \u001b[0m0.0003248\u001b[0m | \u001b[0m16.61    \u001b[0m | \u001b[0m273.7    \u001b[0m | \u001b[0m143.6    \u001b[0m | \u001b[0m42.69    \u001b[0m | \u001b[0m74.4     \u001b[0m |\n",
      "| \u001b[0m28       \u001b[0m | \u001b[0m0.6133   \u001b[0m | \u001b[0m144.4    \u001b[0m | \u001b[0m0.002825 \u001b[0m | \u001b[0m11.58    \u001b[0m | \u001b[0m274.5    \u001b[0m | \u001b[0m142.8    \u001b[0m | \u001b[0m46.02    \u001b[0m | \u001b[0m70.05    \u001b[0m |\n",
      "| \u001b[0m29       \u001b[0m | \u001b[0m0.6223   \u001b[0m | \u001b[0m271.5    \u001b[0m | \u001b[0m0.002023 \u001b[0m | \u001b[0m43.04    \u001b[0m | \u001b[0m350.1    \u001b[0m | \u001b[0m211.4    \u001b[0m | \u001b[0m24.06    \u001b[0m | \u001b[0m66.22    \u001b[0m |\n",
      "| \u001b[0m30       \u001b[0m | \u001b[0m0.6066   \u001b[0m | \u001b[0m130.2    \u001b[0m | \u001b[0m0.005816 \u001b[0m | \u001b[0m14.83    \u001b[0m | \u001b[0m270.5    \u001b[0m | \u001b[0m142.8    \u001b[0m | \u001b[0m45.57    \u001b[0m | \u001b[0m71.91    \u001b[0m |\n",
      "| \u001b[0m31       \u001b[0m | \u001b[0m0.6225   \u001b[0m | \u001b[0m275.1    \u001b[0m | \u001b[0m0.003891 \u001b[0m | \u001b[0m43.51    \u001b[0m | \u001b[0m390.8    \u001b[0m | \u001b[0m254.0    \u001b[0m | \u001b[0m55.09    \u001b[0m | \u001b[0m68.84    \u001b[0m |\n",
      "| \u001b[0m32       \u001b[0m | \u001b[0m0.6135   \u001b[0m | \u001b[0m159.7    \u001b[0m | \u001b[0m0.002959 \u001b[0m | \u001b[0m15.76    \u001b[0m | \u001b[0m275.0    \u001b[0m | \u001b[0m133.7    \u001b[0m | \u001b[0m51.54    \u001b[0m | \u001b[0m91.44    \u001b[0m |\n",
      "| \u001b[0m33       \u001b[0m | \u001b[0m0.6022   \u001b[0m | \u001b[0m274.2    \u001b[0m | \u001b[0m0.00855  \u001b[0m | \u001b[0m40.22    \u001b[0m | \u001b[0m350.8    \u001b[0m | \u001b[0m223.8    \u001b[0m | \u001b[0m17.38    \u001b[0m | \u001b[0m65.09    \u001b[0m |\n",
      "| \u001b[0m34       \u001b[0m | \u001b[0m0.5712   \u001b[0m | \u001b[0m223.7    \u001b[0m | \u001b[0m0.00531  \u001b[0m | \u001b[0m29.23    \u001b[0m | \u001b[0m21.68    \u001b[0m | \u001b[0m153.6    \u001b[0m | \u001b[0m72.42    \u001b[0m | \u001b[0m19.32    \u001b[0m |\n",
      "| \u001b[0m35       \u001b[0m | \u001b[0m0.5908   \u001b[0m | \u001b[0m152.8    \u001b[0m | \u001b[0m0.009372 \u001b[0m | \u001b[0m23.05    \u001b[0m | \u001b[0m271.6    \u001b[0m | \u001b[0m148.0    \u001b[0m | \u001b[0m44.93    \u001b[0m | \u001b[0m75.42    \u001b[0m |\n",
      "| \u001b[0m36       \u001b[0m | \u001b[0m0.6192   \u001b[0m | \u001b[0m286.6    \u001b[0m | \u001b[0m0.004102 \u001b[0m | \u001b[0m33.18    \u001b[0m | \u001b[0m357.8    \u001b[0m | \u001b[0m216.0    \u001b[0m | \u001b[0m65.54    \u001b[0m | \u001b[0m74.32    \u001b[0m |\n",
      "| \u001b[0m37       \u001b[0m | \u001b[0m0.6202   \u001b[0m | \u001b[0m293.1    \u001b[0m | \u001b[0m0.003269 \u001b[0m | \u001b[0m30.04    \u001b[0m | \u001b[0m346.0    \u001b[0m | \u001b[0m216.2    \u001b[0m | \u001b[0m71.87    \u001b[0m | \u001b[0m81.32    \u001b[0m |\n",
      "| \u001b[0m38       \u001b[0m | \u001b[0m0.614    \u001b[0m | \u001b[0m140.9    \u001b[0m | \u001b[0m0.006023 \u001b[0m | \u001b[0m49.28    \u001b[0m | \u001b[0m435.6    \u001b[0m | \u001b[0m243.8    \u001b[0m | \u001b[0m46.81    \u001b[0m | \u001b[0m72.59    \u001b[0m |\n",
      "| \u001b[0m39       \u001b[0m | \u001b[0m0.615    \u001b[0m | \u001b[0m291.5    \u001b[0m | \u001b[0m0.003978 \u001b[0m | \u001b[0m38.74    \u001b[0m | \u001b[0m392.1    \u001b[0m | \u001b[0m246.2    \u001b[0m | \u001b[0m40.56    \u001b[0m | \u001b[0m85.73    \u001b[0m |\n",
      "| \u001b[0m40       \u001b[0m | \u001b[0m0.6209   \u001b[0m | \u001b[0m125.3    \u001b[0m | \u001b[0m0.002095 \u001b[0m | \u001b[0m44.29    \u001b[0m | \u001b[0m436.3    \u001b[0m | \u001b[0m248.4    \u001b[0m | \u001b[0m44.83    \u001b[0m | \u001b[0m64.36    \u001b[0m |\n",
      "=============================================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Define the search space\n",
    "pbounds = {'units1': (16, 512),\n",
    "           'units2': (16, 300),\n",
    "           'units3': (16, 128),\n",
    "           'units4': (16, 128),\n",
    "           'learning_rate': (1e-4, 1e-2),\n",
    "           'batch_size': (120, 300),\n",
    "           'n_epochs': (10, 50)}\n",
    "\n",
    "# Run the optimization\n",
    "optimizer3 = BayesianOptimization(f=objective_function, pbounds=pbounds, random_state=42)\n",
    "optimizer3.maximize(init_points=10, n_iter=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba864b5e",
   "metadata": {},
   "source": [
    "Round 1:\n",
    "\n",
    "Batch size (up) --> target (up)\n",
    "\n",
    "Learning rate (down) --> target (up)\n",
    "\n",
    "n_epochs (up) --> target (up)\n",
    "\n",
    "unit_1 (up) --> target (up)\n",
    "\n",
    "unit_2 (up) --> target (up)\n",
    "\n",
    "unit_3 (down) --> target (up)\n",
    "\n",
    "unit_4 (down) --> target (up)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a67a59c",
   "metadata": {},
   "source": [
    "Round 2:\n",
    "\n",
    "Batch size (up) --> target (up)\n",
    "\n",
    "Learning rate (down) --> target (up)\n",
    "\n",
    "n_epochs (down) --> target (up)\n",
    "\n",
    "unit_1 (down) --> target (up)\n",
    "\n",
    "unit_2 (up) --> target (up)\n",
    "\n",
    "unit_3 (up) --> target (up)\n",
    "\n",
    "unit_4 (down) --> target (up)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "22d7bbbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | batch_... | learni... | n_epochs  |  units1   |  units2   |  units3   |  units4   |\n",
      "-------------------------------------------------------------------------------------------------------------\n",
      "| \u001b[0m1        \u001b[0m | \u001b[0m0.5948   \u001b[0m | \u001b[0m147.5    \u001b[0m | \u001b[0m0.009512 \u001b[0m | \u001b[0m39.28    \u001b[0m | \u001b[0m312.9    \u001b[0m | \u001b[0m60.31    \u001b[0m | \u001b[0m33.47    \u001b[0m | \u001b[0m22.51    \u001b[0m |\n",
      "| \u001b[0m2        \u001b[0m | \u001b[0m0.5655   \u001b[0m | \u001b[0m157.3    \u001b[0m | \u001b[0m0.006051 \u001b[0m | \u001b[0m38.32    \u001b[0m | \u001b[0m26.21    \u001b[0m | \u001b[0m291.5    \u001b[0m | \u001b[0m109.2    \u001b[0m | \u001b[0m39.78    \u001b[0m |\n",
      "| \u001b[95m3        \u001b[0m | \u001b[95m0.6273   \u001b[0m | \u001b[95m143.6    \u001b[0m | \u001b[95m0.001916 \u001b[0m | \u001b[95m22.17    \u001b[0m | \u001b[95m276.3    \u001b[0m | \u001b[95m138.7    \u001b[0m | \u001b[95m48.62    \u001b[0m | \u001b[95m84.53    \u001b[0m |\n",
      "| \u001b[0m4        \u001b[0m | \u001b[0m0.6085   \u001b[0m | \u001b[0m142.8    \u001b[0m | \u001b[0m0.002992 \u001b[0m | \u001b[0m24.65    \u001b[0m | \u001b[0m242.2    \u001b[0m | \u001b[0m239.0    \u001b[0m | \u001b[0m38.36    \u001b[0m | \u001b[0m73.59    \u001b[0m |\n",
      "| \u001b[0m5        \u001b[0m | \u001b[0m0.6038   \u001b[0m | \u001b[0m151.8    \u001b[0m | \u001b[0m0.0005599\u001b[0m | \u001b[0m34.3     \u001b[0m | \u001b[0m100.6    \u001b[0m | \u001b[0m34.47    \u001b[0m | \u001b[0m122.3    \u001b[0m | \u001b[0m124.2    \u001b[0m |\n",
      "| \u001b[0m6        \u001b[0m | \u001b[0m0.6234   \u001b[0m | \u001b[0m156.2    \u001b[0m | \u001b[0m0.003116 \u001b[0m | \u001b[0m13.91    \u001b[0m | \u001b[0m355.4    \u001b[0m | \u001b[0m141.0    \u001b[0m | \u001b[0m29.67    \u001b[0m | \u001b[0m71.46    \u001b[0m |\n",
      "| \u001b[0m7        \u001b[0m | \u001b[0m0.5995   \u001b[0m | \u001b[0m140.7    \u001b[0m | \u001b[0m0.009102 \u001b[0m | \u001b[0m20.35    \u001b[0m | \u001b[0m344.6    \u001b[0m | \u001b[0m104.5    \u001b[0m | \u001b[0m74.25    \u001b[0m | \u001b[0m77.23    \u001b[0m |\n",
      "| \u001b[0m8        \u001b[0m | \u001b[0m0.5817   \u001b[0m | \u001b[0m143.7    \u001b[0m | \u001b[0m0.009699 \u001b[0m | \u001b[0m41.01    \u001b[0m | \u001b[0m482.0    \u001b[0m | \u001b[0m270.1    \u001b[0m | \u001b[0m82.96    \u001b[0m | \u001b[0m119.2    \u001b[0m |\n",
      "| \u001b[0m9        \u001b[0m | \u001b[0m0.6184   \u001b[0m | \u001b[0m141.8    \u001b[0m | \u001b[0m0.00204  \u001b[0m | \u001b[0m11.81    \u001b[0m | \u001b[0m177.4    \u001b[0m | \u001b[0m126.4    \u001b[0m | \u001b[0m46.39    \u001b[0m | \u001b[0m108.8    \u001b[0m |\n",
      "| \u001b[0m10       \u001b[0m | \u001b[0m0.6116   \u001b[0m | \u001b[0m147.1    \u001b[0m | \u001b[0m0.002881 \u001b[0m | \u001b[0m31.71    \u001b[0m | \u001b[0m85.9     \u001b[0m | \u001b[0m243.8    \u001b[0m | \u001b[0m24.35    \u001b[0m | \u001b[0m126.5    \u001b[0m |\n",
      "| \u001b[95m11       \u001b[0m | \u001b[95m0.6308   \u001b[0m | \u001b[95m149.6    \u001b[0m | \u001b[95m0.001261 \u001b[0m | \u001b[95m15.01    \u001b[0m | \u001b[95m356.0    \u001b[0m | \u001b[95m138.2    \u001b[0m | \u001b[95m38.46    \u001b[0m | \u001b[95m71.06    \u001b[0m |\n",
      "| \u001b[0m12       \u001b[0m | \u001b[0m0.6179   \u001b[0m | \u001b[0m149.0    \u001b[0m | \u001b[0m0.003385 \u001b[0m | \u001b[0m24.74    \u001b[0m | \u001b[0m283.7    \u001b[0m | \u001b[0m128.5    \u001b[0m | \u001b[0m51.54    \u001b[0m | \u001b[0m85.82    \u001b[0m |\n",
      "| \u001b[0m13       \u001b[0m | \u001b[0m0.6094   \u001b[0m | \u001b[0m141.3    \u001b[0m | \u001b[0m0.004367 \u001b[0m | \u001b[0m14.07    \u001b[0m | \u001b[0m241.2    \u001b[0m | \u001b[0m237.1    \u001b[0m | \u001b[0m43.34    \u001b[0m | \u001b[0m81.29    \u001b[0m |\n",
      "| \u001b[0m14       \u001b[0m | \u001b[0m0.6094   \u001b[0m | \u001b[0m151.2    \u001b[0m | \u001b[0m0.003067 \u001b[0m | \u001b[0m21.94    \u001b[0m | \u001b[0m360.2    \u001b[0m | \u001b[0m141.7    \u001b[0m | \u001b[0m27.49    \u001b[0m | \u001b[0m75.43    \u001b[0m |\n",
      "| \u001b[0m15       \u001b[0m | \u001b[0m0.6222   \u001b[0m | \u001b[0m157.4    \u001b[0m | \u001b[0m0.001695 \u001b[0m | \u001b[0m19.11    \u001b[0m | \u001b[0m363.6    \u001b[0m | \u001b[0m132.2    \u001b[0m | \u001b[0m36.51    \u001b[0m | \u001b[0m68.09    \u001b[0m |\n",
      "| \u001b[0m16       \u001b[0m | \u001b[0m0.5948   \u001b[0m | \u001b[0m155.3    \u001b[0m | \u001b[0m0.00937  \u001b[0m | \u001b[0m29.09    \u001b[0m | \u001b[0m366.3    \u001b[0m | \u001b[0m134.7    \u001b[0m | \u001b[0m43.2     \u001b[0m | \u001b[0m73.9     \u001b[0m |\n",
      "| \u001b[0m17       \u001b[0m | \u001b[0m0.6066   \u001b[0m | \u001b[0m147.8    \u001b[0m | \u001b[0m0.00658  \u001b[0m | \u001b[0m10.97    \u001b[0m | \u001b[0m365.9    \u001b[0m | \u001b[0m134.3    \u001b[0m | \u001b[0m43.96    \u001b[0m | \u001b[0m52.75    \u001b[0m |\n",
      "| \u001b[0m18       \u001b[0m | \u001b[0m0.6101   \u001b[0m | \u001b[0m143.8    \u001b[0m | \u001b[0m0.007489 \u001b[0m | \u001b[0m15.02    \u001b[0m | \u001b[0m343.6    \u001b[0m | \u001b[0m134.2    \u001b[0m | \u001b[0m25.72    \u001b[0m | \u001b[0m62.29    \u001b[0m |\n",
      "| \u001b[0m19       \u001b[0m | \u001b[0m0.5971   \u001b[0m | \u001b[0m140.3    \u001b[0m | \u001b[0m0.006324 \u001b[0m | \u001b[0m16.31    \u001b[0m | \u001b[0m177.2    \u001b[0m | \u001b[0m127.9    \u001b[0m | \u001b[0m40.35    \u001b[0m | \u001b[0m109.8    \u001b[0m |\n",
      "| \u001b[0m20       \u001b[0m | \u001b[0m0.6129   \u001b[0m | \u001b[0m148.6    \u001b[0m | \u001b[0m0.00334  \u001b[0m | \u001b[0m30.7     \u001b[0m | \u001b[0m502.8    \u001b[0m | \u001b[0m20.78    \u001b[0m | \u001b[0m115.7    \u001b[0m | \u001b[0m74.18    \u001b[0m |\n",
      "| \u001b[0m21       \u001b[0m | \u001b[0m0.6112   \u001b[0m | \u001b[0m149.1    \u001b[0m | \u001b[0m0.004025 \u001b[0m | \u001b[0m19.08    \u001b[0m | \u001b[0m357.1    \u001b[0m | \u001b[0m143.7    \u001b[0m | \u001b[0m37.87    \u001b[0m | \u001b[0m60.64    \u001b[0m |\n",
      "| \u001b[0m22       \u001b[0m | \u001b[0m0.5565   \u001b[0m | \u001b[0m155.6    \u001b[0m | \u001b[0m0.007172 \u001b[0m | \u001b[0m33.94    \u001b[0m | \u001b[0m28.9     \u001b[0m | \u001b[0m141.6    \u001b[0m | \u001b[0m79.77    \u001b[0m | \u001b[0m91.68    \u001b[0m |\n",
      "| \u001b[0m23       \u001b[0m | \u001b[0m0.5742   \u001b[0m | \u001b[0m146.7    \u001b[0m | \u001b[0m0.009662 \u001b[0m | \u001b[0m13.78    \u001b[0m | \u001b[0m249.9    \u001b[0m | \u001b[0m292.3    \u001b[0m | \u001b[0m81.25    \u001b[0m | \u001b[0m103.6    \u001b[0m |\n",
      "| \u001b[0m24       \u001b[0m | \u001b[0m0.6136   \u001b[0m | \u001b[0m144.0    \u001b[0m | \u001b[0m0.004447 \u001b[0m | \u001b[0m25.63    \u001b[0m | \u001b[0m272.8    \u001b[0m | \u001b[0m137.5    \u001b[0m | \u001b[0m41.63    \u001b[0m | \u001b[0m97.36    \u001b[0m |\n",
      "| \u001b[0m25       \u001b[0m | \u001b[0m0.6218   \u001b[0m | \u001b[0m151.4    \u001b[0m | \u001b[0m0.002552 \u001b[0m | \u001b[0m12.66    \u001b[0m | \u001b[0m345.6    \u001b[0m | \u001b[0m127.9    \u001b[0m | \u001b[0m54.76    \u001b[0m | \u001b[0m74.39    \u001b[0m |\n",
      "| \u001b[0m26       \u001b[0m | \u001b[0m0.5945   \u001b[0m | \u001b[0m158.8    \u001b[0m | \u001b[0m0.007928 \u001b[0m | \u001b[0m20.17    \u001b[0m | \u001b[0m360.8    \u001b[0m | \u001b[0m78.73    \u001b[0m | \u001b[0m88.63    \u001b[0m | \u001b[0m98.5     \u001b[0m |\n",
      "| \u001b[0m27       \u001b[0m | \u001b[0m0.604    \u001b[0m | \u001b[0m153.5    \u001b[0m | \u001b[0m0.005018 \u001b[0m | \u001b[0m32.14    \u001b[0m | \u001b[0m149.7    \u001b[0m | \u001b[0m135.5    \u001b[0m | \u001b[0m43.43    \u001b[0m | \u001b[0m127.0    \u001b[0m |\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_11384\\3828061703.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m# Run the optimization\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0moptimizer4\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBayesianOptimization\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mobjective_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpbounds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpbounds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m42\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0moptimizer4\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmaximize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minit_points\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\bayes_opt\\bayesian_optimization.py\u001b[0m in \u001b[0;36mmaximize\u001b[1;34m(self, init_points, n_iter, acquisition_function, acq, kappa, kappa_decay, kappa_decay_delay, xi, **gp_params)\u001b[0m\n\u001b[0;32m    309\u001b[0m                 \u001b[0mx_probe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msuggest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mutil\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 \u001b[0miteration\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprobe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_probe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlazy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_bounds_transformer\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0miteration\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\bayes_opt\\bayesian_optimization.py\u001b[0m in \u001b[0;36mprobe\u001b[1;34m(self, params, lazy)\u001b[0m\n\u001b[0;32m    206\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_queue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_space\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprobe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOPTIMIZATION_STEP\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\bayes_opt\\target_space.py\u001b[0m in \u001b[0;36mprobe\u001b[1;34m(self, params)\u001b[0m\n\u001b[0;32m    234\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_as_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    235\u001b[0m         \u001b[0mparams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_keys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 236\u001b[1;33m         \u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    237\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    238\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_constraint\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_11384\\3683193273.py\u001b[0m in \u001b[0;36mobjective_function\u001b[1;34m(units1, units2, units3, units4, learning_rate, batch_size, n_epochs)\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mearly_stop\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mEarlyStopping\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'val_loss'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrestore_best_weights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m     \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mearly_stop\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[0mval_acc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1562\u001b[0m                         ):\n\u001b[0;32m   1563\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1564\u001b[1;33m                             \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1565\u001b[0m                             \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1566\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    878\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    879\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 880\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    881\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    882\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    910\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    911\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 912\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_no_variable_creation_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    913\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_variable_creation_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    914\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    132\u001b[0m       (concrete_function,\n\u001b[0;32m    133\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m--> 134\u001b[1;33m     return concrete_function._call_flat(\n\u001b[0m\u001b[0;32m    135\u001b[0m         filtered_flat_args, captured_inputs=concrete_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m    136\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1743\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1744\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1745\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1746\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    376\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    377\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 378\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    379\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    380\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     50\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     53\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     54\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Define the search space\n",
    "pbounds = {'units1': (16, 512),\n",
    "           'units2': (16, 300),\n",
    "           'units3': (16, 128),\n",
    "           'units4': (16, 128),\n",
    "           'learning_rate': (1e-4, 1e-2),\n",
    "           'batch_size': (140, 160), #tune batch size\n",
    "           'n_epochs': (10, 50)}\n",
    "\n",
    "# Run the optimization\n",
    "optimizer4 = BayesianOptimization(f=objective_function, pbounds=pbounds, random_state=42)\n",
    "optimizer4.maximize(init_points=10, n_iter=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "032bf64b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | batch_... | learni... | n_epochs  |  units1   |  units2   |  units3   |  units4   |\n",
      "-------------------------------------------------------------------------------------------------------------\n",
      "| \u001b[0m1        \u001b[0m | \u001b[0m0.6077   \u001b[0m | \u001b[0m343.6    \u001b[0m | \u001b[0m0.009508 \u001b[0m | \u001b[0m41.96    \u001b[0m | \u001b[0m409.9    \u001b[0m | \u001b[0m256.5    \u001b[0m | \u001b[0m43.12    \u001b[0m | \u001b[0m51.74    \u001b[0m |\n",
      "| \u001b[0m2        \u001b[0m | \u001b[0m0.6041   \u001b[0m | \u001b[0m466.5    \u001b[0m | \u001b[0m0.006015 \u001b[0m | \u001b[0m41.24    \u001b[0m | \u001b[0m352.1    \u001b[0m | \u001b[0m394.9    \u001b[0m | \u001b[0m56.65    \u001b[0m | \u001b[0m56.37    \u001b[0m |\n",
      "| \u001b[95m3        \u001b[0m | \u001b[95m0.6257   \u001b[0m | \u001b[95m295.5    \u001b[0m | \u001b[95m0.001842 \u001b[0m | \u001b[95m29.13    \u001b[0m | \u001b[95m402.5    \u001b[0m | \u001b[95m303.4    \u001b[0m | \u001b[95m45.82    \u001b[0m | \u001b[95m68.36    \u001b[0m |\n",
      "| \u001b[0m4        \u001b[0m | \u001b[0m0.6221   \u001b[0m | \u001b[0m284.9    \u001b[0m | \u001b[0m0.002929 \u001b[0m | \u001b[0m30.99    \u001b[0m | \u001b[0m395.6    \u001b[0m | \u001b[0m363.5    \u001b[0m | \u001b[0m43.99    \u001b[0m | \u001b[0m65.43    \u001b[0m |\n",
      "| \u001b[95m5        \u001b[0m | \u001b[95m0.6268   \u001b[0m | \u001b[95m398.1    \u001b[0m | \u001b[95m0.000474 \u001b[0m | \u001b[95m38.23    \u001b[0m | \u001b[95m367.1    \u001b[0m | \u001b[95m241.1    \u001b[0m | \u001b[95m58.98    \u001b[0m | \u001b[95m78.97    \u001b[0m |\n",
      "| \u001b[0m6        \u001b[0m | \u001b[0m0.6226   \u001b[0m | \u001b[0m452.1    \u001b[0m | \u001b[0m0.003053 \u001b[0m | \u001b[0m22.93    \u001b[0m | \u001b[0m418.4    \u001b[0m | \u001b[0m304.8    \u001b[0m | \u001b[0m42.44    \u001b[0m | \u001b[0m64.86    \u001b[0m |\n",
      "| \u001b[0m7        \u001b[0m | \u001b[0m0.6049   \u001b[0m | \u001b[0m258.6    \u001b[0m | \u001b[0m0.009094 \u001b[0m | \u001b[0m27.76    \u001b[0m | \u001b[0m416.3    \u001b[0m | \u001b[0m283.0    \u001b[0m | \u001b[0m50.4     \u001b[0m | \u001b[0m66.4     \u001b[0m |\n",
      "| \u001b[0m8        \u001b[0m | \u001b[0m0.5982   \u001b[0m | \u001b[0m296.2    \u001b[0m | \u001b[0m0.009696 \u001b[0m | \u001b[0m43.25    \u001b[0m | \u001b[0m443.9    \u001b[0m | \u001b[0m382.1    \u001b[0m | \u001b[0m51.96    \u001b[0m | \u001b[0m77.66    \u001b[0m |\n",
      "| \u001b[0m9        \u001b[0m | \u001b[0m0.6223   \u001b[0m | \u001b[0m272.1    \u001b[0m | \u001b[0m0.001968 \u001b[0m | \u001b[0m21.36    \u001b[0m | \u001b[0m382.5    \u001b[0m | \u001b[0m296.1    \u001b[0m | \u001b[0m45.43    \u001b[0m | \u001b[0m74.86    \u001b[0m |\n",
      "| \u001b[0m10       \u001b[0m | \u001b[0m0.6213   \u001b[0m | \u001b[0m339.2    \u001b[0m | \u001b[0m0.002817 \u001b[0m | \u001b[0m36.28    \u001b[0m | \u001b[0m364.1    \u001b[0m | \u001b[0m366.4    \u001b[0m | \u001b[0m41.49    \u001b[0m | \u001b[0m79.61    \u001b[0m |\n",
      "| \u001b[0m11       \u001b[0m | \u001b[0m0.5949   \u001b[0m | \u001b[0m285.9    \u001b[0m | \u001b[0m0.009786 \u001b[0m | \u001b[0m21.36    \u001b[0m | \u001b[0m396.8    \u001b[0m | \u001b[0m302.3    \u001b[0m | \u001b[0m47.2     \u001b[0m | \u001b[0m73.46    \u001b[0m |\n",
      "| \u001b[95m12       \u001b[0m | \u001b[95m0.635    \u001b[0m | \u001b[95m266.1    \u001b[0m | \u001b[95m0.001099 \u001b[0m | \u001b[95m46.89    \u001b[0m | \u001b[95m435.0    \u001b[0m | \u001b[95m357.8    \u001b[0m | \u001b[95m45.58    \u001b[0m | \u001b[95m64.93    \u001b[0m |\n",
      "| \u001b[0m13       \u001b[0m | \u001b[0m0.6209   \u001b[0m | \u001b[0m356.4    \u001b[0m | \u001b[0m0.003414 \u001b[0m | \u001b[0m47.15    \u001b[0m | \u001b[0m397.3    \u001b[0m | \u001b[0m390.2    \u001b[0m | \u001b[0m45.94    \u001b[0m | \u001b[0m70.41    \u001b[0m |\n",
      "| \u001b[0m14       \u001b[0m | \u001b[0m0.6285   \u001b[0m | \u001b[0m499.6    \u001b[0m | \u001b[0m0.0005211\u001b[0m | \u001b[0m43.48    \u001b[0m | \u001b[0m424.2    \u001b[0m | \u001b[0m364.7    \u001b[0m | \u001b[0m46.99    \u001b[0m | \u001b[0m63.93    \u001b[0m |\n",
      "| \u001b[0m15       \u001b[0m | \u001b[0m0.5991   \u001b[0m | \u001b[0m389.0    \u001b[0m | \u001b[0m0.009038 \u001b[0m | \u001b[0m39.85    \u001b[0m | \u001b[0m373.1    \u001b[0m | \u001b[0m394.2    \u001b[0m | \u001b[0m47.92    \u001b[0m | \u001b[0m50.83    \u001b[0m |\n",
      "| \u001b[0m16       \u001b[0m | \u001b[0m0.627    \u001b[0m | \u001b[0m452.3    \u001b[0m | \u001b[0m0.001936 \u001b[0m | \u001b[0m45.52    \u001b[0m | \u001b[0m415.1    \u001b[0m | \u001b[0m342.7    \u001b[0m | \u001b[0m41.02    \u001b[0m | \u001b[0m62.56    \u001b[0m |\n",
      "| \u001b[0m17       \u001b[0m | \u001b[0m0.6104   \u001b[0m | \u001b[0m427.4    \u001b[0m | \u001b[0m0.006319 \u001b[0m | \u001b[0m44.05    \u001b[0m | \u001b[0m417.4    \u001b[0m | \u001b[0m373.6    \u001b[0m | \u001b[0m44.31    \u001b[0m | \u001b[0m78.8     \u001b[0m |\n",
      "| \u001b[0m18       \u001b[0m | \u001b[0m0.605    \u001b[0m | \u001b[0m279.8    \u001b[0m | \u001b[0m0.009504 \u001b[0m | \u001b[0m49.05    \u001b[0m | \u001b[0m445.3    \u001b[0m | \u001b[0m387.2    \u001b[0m | \u001b[0m44.73    \u001b[0m | \u001b[0m62.64    \u001b[0m |\n",
      "| \u001b[0m19       \u001b[0m | \u001b[0m0.6154   \u001b[0m | \u001b[0m494.1    \u001b[0m | \u001b[0m0.007002 \u001b[0m | \u001b[0m47.09    \u001b[0m | \u001b[0m394.5    \u001b[0m | \u001b[0m299.4    \u001b[0m | \u001b[0m44.81    \u001b[0m | \u001b[0m55.37    \u001b[0m |\n",
      "| \u001b[0m20       \u001b[0m | \u001b[0m0.6162   \u001b[0m | \u001b[0m357.1    \u001b[0m | \u001b[0m0.003279 \u001b[0m | \u001b[0m35.53    \u001b[0m | \u001b[0m448.1    \u001b[0m | \u001b[0m232.9    \u001b[0m | \u001b[0m57.81    \u001b[0m | \u001b[0m65.58    \u001b[0m |\n",
      "| \u001b[0m21       \u001b[0m | \u001b[0m0.6098   \u001b[0m | \u001b[0m251.6    \u001b[0m | \u001b[0m0.004835 \u001b[0m | \u001b[0m28.73    \u001b[0m | \u001b[0m408.6    \u001b[0m | \u001b[0m316.9    \u001b[0m | \u001b[0m43.19    \u001b[0m | \u001b[0m78.99    \u001b[0m |\n",
      "| \u001b[0m22       \u001b[0m | \u001b[0m0.6115   \u001b[0m | \u001b[0m444.4    \u001b[0m | \u001b[0m0.007146 \u001b[0m | \u001b[0m37.96    \u001b[0m | \u001b[0m352.6    \u001b[0m | \u001b[0m305.2    \u001b[0m | \u001b[0m51.39    \u001b[0m | \u001b[0m70.27    \u001b[0m |\n",
      "| \u001b[0m23       \u001b[0m | \u001b[0m0.6013   \u001b[0m | \u001b[0m334.3    \u001b[0m | \u001b[0m0.009659 \u001b[0m | \u001b[0m22.84    \u001b[0m | \u001b[0m397.2    \u001b[0m | \u001b[0m395.4    \u001b[0m | \u001b[0m51.65    \u001b[0m | \u001b[0m73.48    \u001b[0m |\n",
      "| \u001b[0m24       \u001b[0m | \u001b[0m0.5922   \u001b[0m | \u001b[0m373.5    \u001b[0m | \u001b[0m0.008075 \u001b[0m | \u001b[0m36.51    \u001b[0m | \u001b[0m445.3    \u001b[0m | \u001b[0m310.1    \u001b[0m | \u001b[0m58.81    \u001b[0m | \u001b[0m59.44    \u001b[0m |\n",
      "| \u001b[0m25       \u001b[0m | \u001b[0m0.6225   \u001b[0m | \u001b[0m436.6    \u001b[0m | \u001b[0m0.003391 \u001b[0m | \u001b[0m33.6     \u001b[0m | \u001b[0m415.6    \u001b[0m | \u001b[0m336.4    \u001b[0m | \u001b[0m44.1     \u001b[0m | \u001b[0m72.42    \u001b[0m |\n",
      "=============================================================================================================\n"
     ]
    }
   ],
   "source": [
    "# re-tuned\n",
    "# Define the search space\n",
    "pbounds = {'units1': (350, 450),\n",
    "           'units2': (230, 400),\n",
    "           'units3': (40, 60),\n",
    "           'units4': (50, 80),\n",
    "           'learning_rate': (1e-5, 1e-2),\n",
    "           'batch_size': (250, 500), #tune batch size\n",
    "           'n_epochs': (20, 50)}\n",
    "\n",
    "# Run the optimization\n",
    "optimizer4 = BayesianOptimization(f=objective_function, pbounds=pbounds, random_state=42)\n",
    "optimizer4.maximize(init_points=10, n_iter=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "80ab8168",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'batch_size': 266.0927003345415, 'learning_rate': 0.001098609322769119, 'n_epochs': 46.892362254235735, 'units1': 434.9946745178665, 'units2': 357.8159679372243, 'units3': 45.57874587181616, 'units4': 64.93450859931866}\n",
      "Validation accuracy: 0.6350\n"
     ]
    }
   ],
   "source": [
    "# Print the best hyperparameters and validation accuracy\n",
    "best_params = optimizer5.max['params']\n",
    "best_val_acc = optimizer5.max['target']\n",
    "print(f'Best hyperparameters: {best_params}')\n",
    "print(f'Validation accuracy: {best_val_acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "030b43aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | batch_... | learni... | n_epochs  |  units1   |  units2   |  units3   |  units4   |\n",
      "-------------------------------------------------------------------------------------------------------------\n",
      "| \u001b[0m1        \u001b[0m | \u001b[0m0.6274   \u001b[0m | \u001b[0m237.4    \u001b[0m | \u001b[0m0.0009556\u001b[0m | \u001b[0m31.96    \u001b[0m | \u001b[0m459.9    \u001b[0m | \u001b[0m357.8    \u001b[0m | \u001b[0m43.12    \u001b[0m | \u001b[0m51.74    \u001b[0m |\n",
      "| \u001b[95m2        \u001b[0m | \u001b[95m0.6343   \u001b[0m | \u001b[95m365.2    \u001b[0m | \u001b[95m0.000641 \u001b[0m | \u001b[95m31.24    \u001b[0m | \u001b[95m402.1    \u001b[0m | \u001b[95m398.5    \u001b[0m | \u001b[95m56.65    \u001b[0m | \u001b[95m56.37    \u001b[0m |\n",
      "| \u001b[0m3        \u001b[0m | \u001b[0m0.6279   \u001b[0m | \u001b[0m187.3    \u001b[0m | \u001b[0m0.0002651\u001b[0m | \u001b[0m19.13    \u001b[0m | \u001b[0m452.5    \u001b[0m | \u001b[0m371.6    \u001b[0m | \u001b[0m45.82    \u001b[0m | \u001b[0m68.36    \u001b[0m |\n",
      "| \u001b[0m4        \u001b[0m | \u001b[0m0.6178   \u001b[0m | \u001b[0m176.3    \u001b[0m | \u001b[0m0.0003629\u001b[0m | \u001b[0m20.99    \u001b[0m | \u001b[0m445.6    \u001b[0m | \u001b[0m389.3    \u001b[0m | \u001b[0m43.99    \u001b[0m | \u001b[0m65.43    \u001b[0m |\n",
      "| \u001b[0m5        \u001b[0m | \u001b[0m0.6082   \u001b[0m | \u001b[0m294.0    \u001b[0m | \u001b[0m0.0001418\u001b[0m | \u001b[0m28.23    \u001b[0m | \u001b[0m417.1    \u001b[0m | \u001b[0m353.3    \u001b[0m | \u001b[0m58.98    \u001b[0m | \u001b[0m78.97    \u001b[0m |\n",
      "| \u001b[0m6        \u001b[0m | \u001b[0m0.6103   \u001b[0m | \u001b[0m350.2    \u001b[0m | \u001b[0m0.0003742\u001b[0m | \u001b[0m12.93    \u001b[0m | \u001b[0m468.4    \u001b[0m | \u001b[0m372.0    \u001b[0m | \u001b[0m42.44    \u001b[0m | \u001b[0m64.86    \u001b[0m |\n",
      "| \u001b[0m7        \u001b[0m | \u001b[0m0.6273   \u001b[0m | \u001b[0m148.9    \u001b[0m | \u001b[0m0.0009184\u001b[0m | \u001b[0m17.76    \u001b[0m | \u001b[0m466.3    \u001b[0m | \u001b[0m365.6    \u001b[0m | \u001b[0m50.4     \u001b[0m | \u001b[0m66.4     \u001b[0m |\n",
      "| \u001b[0m8        \u001b[0m | \u001b[0m0.6317   \u001b[0m | \u001b[0m188.1    \u001b[0m | \u001b[0m0.0009726\u001b[0m | \u001b[0m33.25    \u001b[0m | \u001b[0m493.9    \u001b[0m | \u001b[0m394.7    \u001b[0m | \u001b[0m51.96    \u001b[0m | \u001b[0m77.66    \u001b[0m |\n",
      "| \u001b[0m9        \u001b[0m | \u001b[0m0.607    \u001b[0m | \u001b[0m163.0    \u001b[0m | \u001b[0m0.0002764\u001b[0m | \u001b[0m11.36    \u001b[0m | \u001b[0m432.5    \u001b[0m | \u001b[0m369.4    \u001b[0m | \u001b[0m45.43    \u001b[0m | \u001b[0m74.86    \u001b[0m |\n",
      "| \u001b[0m10       \u001b[0m | \u001b[0m0.6277   \u001b[0m | \u001b[0m232.8    \u001b[0m | \u001b[0m0.0003528\u001b[0m | \u001b[0m26.28    \u001b[0m | \u001b[0m414.1    \u001b[0m | \u001b[0m390.1    \u001b[0m | \u001b[0m41.49    \u001b[0m | \u001b[0m79.61    \u001b[0m |\n",
      "| \u001b[0m11       \u001b[0m | \u001b[0m0.6307   \u001b[0m | \u001b[0m238.4    \u001b[0m | \u001b[0m0.0004047\u001b[0m | \u001b[0m35.55    \u001b[0m | \u001b[0m457.2    \u001b[0m | \u001b[0m359.3    \u001b[0m | \u001b[0m40.57    \u001b[0m | \u001b[0m53.07    \u001b[0m |\n",
      "| \u001b[0m12       \u001b[0m | \u001b[0m0.6241   \u001b[0m | \u001b[0m374.8    \u001b[0m | \u001b[0m0.0003766\u001b[0m | \u001b[0m36.31    \u001b[0m | \u001b[0m405.5    \u001b[0m | \u001b[0m383.9    \u001b[0m | \u001b[0m50.55    \u001b[0m | \u001b[0m58.3     \u001b[0m |\n",
      "| \u001b[0m13       \u001b[0m | \u001b[0m0.6109   \u001b[0m | \u001b[0m352.0    \u001b[0m | \u001b[0m0.0004919\u001b[0m | \u001b[0m24.56    \u001b[0m | \u001b[0m400.6    \u001b[0m | \u001b[0m393.3    \u001b[0m | \u001b[0m59.68    \u001b[0m | \u001b[0m63.53    \u001b[0m |\n",
      "| \u001b[0m14       \u001b[0m | \u001b[0m0.6201   \u001b[0m | \u001b[0m370.2    \u001b[0m | \u001b[0m0.0005541\u001b[0m | \u001b[0m31.76    \u001b[0m | \u001b[0m406.7    \u001b[0m | \u001b[0m399.2    \u001b[0m | \u001b[0m51.81    \u001b[0m | \u001b[0m56.95    \u001b[0m |\n",
      "| \u001b[0m15       \u001b[0m | \u001b[0m0.6296   \u001b[0m | \u001b[0m190.5    \u001b[0m | \u001b[0m0.0006988\u001b[0m | \u001b[0m32.85    \u001b[0m | \u001b[0m491.2    \u001b[0m | \u001b[0m396.3    \u001b[0m | \u001b[0m56.83    \u001b[0m | \u001b[0m80.0     \u001b[0m |\n",
      "| \u001b[0m16       \u001b[0m | \u001b[0m0.6328   \u001b[0m | \u001b[0m184.0    \u001b[0m | \u001b[0m0.0007095\u001b[0m | \u001b[0m25.56    \u001b[0m | \u001b[0m495.8    \u001b[0m | \u001b[0m395.1    \u001b[0m | \u001b[0m54.16    \u001b[0m | \u001b[0m76.27    \u001b[0m |\n",
      "| \u001b[0m17       \u001b[0m | \u001b[0m0.633    \u001b[0m | \u001b[0m183.9    \u001b[0m | \u001b[0m0.0003254\u001b[0m | \u001b[0m24.62    \u001b[0m | \u001b[0m491.6    \u001b[0m | \u001b[0m394.2    \u001b[0m | \u001b[0m45.71    \u001b[0m | \u001b[0m77.11    \u001b[0m |\n",
      "| \u001b[0m18       \u001b[0m | \u001b[0m0.6309   \u001b[0m | \u001b[0m179.9    \u001b[0m | \u001b[0m0.0003194\u001b[0m | \u001b[0m30.06    \u001b[0m | \u001b[0m487.2    \u001b[0m | \u001b[0m398.0    \u001b[0m | \u001b[0m51.7     \u001b[0m | \u001b[0m73.04    \u001b[0m |\n",
      "| \u001b[0m19       \u001b[0m | \u001b[0m0.6286   \u001b[0m | \u001b[0m185.7    \u001b[0m | \u001b[0m0.0009375\u001b[0m | \u001b[0m25.79    \u001b[0m | \u001b[0m497.3    \u001b[0m | \u001b[0m387.0    \u001b[0m | \u001b[0m47.82    \u001b[0m | \u001b[0m67.05    \u001b[0m |\n",
      "| \u001b[0m20       \u001b[0m | \u001b[0m0.6282   \u001b[0m | \u001b[0m180.6    \u001b[0m | \u001b[0m0.001    \u001b[0m | \u001b[0m28.17    \u001b[0m | \u001b[0m489.3    \u001b[0m | \u001b[0m385.7    \u001b[0m | \u001b[0m52.88    \u001b[0m | \u001b[0m79.98    \u001b[0m |\n",
      "| \u001b[0m21       \u001b[0m | \u001b[0m0.6223   \u001b[0m | \u001b[0m180.7    \u001b[0m | \u001b[0m0.0005038\u001b[0m | \u001b[0m14.18    \u001b[0m | \u001b[0m487.7    \u001b[0m | \u001b[0m393.9    \u001b[0m | \u001b[0m44.93    \u001b[0m | \u001b[0m69.31    \u001b[0m |\n",
      "| \u001b[0m22       \u001b[0m | \u001b[0m0.626    \u001b[0m | \u001b[0m196.2    \u001b[0m | \u001b[0m0.0006716\u001b[0m | \u001b[0m22.13    \u001b[0m | \u001b[0m490.0    \u001b[0m | \u001b[0m393.1    \u001b[0m | \u001b[0m50.53    \u001b[0m | \u001b[0m77.07    \u001b[0m |\n",
      "| \u001b[0m23       \u001b[0m | \u001b[0m0.6335   \u001b[0m | \u001b[0m189.9    \u001b[0m | \u001b[0m0.0007905\u001b[0m | \u001b[0m33.48    \u001b[0m | \u001b[0m481.9    \u001b[0m | \u001b[0m398.6    \u001b[0m | \u001b[0m47.03    \u001b[0m | \u001b[0m77.16    \u001b[0m |\n",
      "| \u001b[0m24       \u001b[0m | \u001b[0m0.6298   \u001b[0m | \u001b[0m191.7    \u001b[0m | \u001b[0m0.0009132\u001b[0m | \u001b[0m39.37    \u001b[0m | \u001b[0m485.3    \u001b[0m | \u001b[0m393.7    \u001b[0m | \u001b[0m48.59    \u001b[0m | \u001b[0m66.6     \u001b[0m |\n",
      "| \u001b[0m25       \u001b[0m | \u001b[0m0.6158   \u001b[0m | \u001b[0m193.6    \u001b[0m | \u001b[0m0.0003226\u001b[0m | \u001b[0m36.43    \u001b[0m | \u001b[0m472.1    \u001b[0m | \u001b[0m390.2    \u001b[0m | \u001b[0m41.52    \u001b[0m | \u001b[0m76.16    \u001b[0m |\n",
      "=============================================================================================================\n"
     ]
    }
   ],
   "source": [
    "# re-tuned\n",
    "# Define the search space\n",
    "pbounds = {'units1': (400, 500),\n",
    "           'units2': (350, 400),\n",
    "           'units3': (40, 60),\n",
    "           'units4': (50, 80),\n",
    "           'learning_rate': (1e-4, 1e-3),\n",
    "           'batch_size': (140, 400), #tune batch size\n",
    "           'n_epochs': (10, 40)}\n",
    "\n",
    "# Run the optimization\n",
    "optimizer5 = BayesianOptimization(f=objective_function, pbounds=pbounds, random_state=42)\n",
    "optimizer5.maximize(init_points=10, n_iter=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "299340f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | batch_... | learni... | n_epochs  |  units1   |  units2   |  units3   |  units4   |\n",
      "-------------------------------------------------------------------------------------------------------------\n",
      "| \u001b[0m1        \u001b[0m | \u001b[0m0.626    \u001b[0m | \u001b[0m237.4    \u001b[0m | \u001b[0m0.0009556\u001b[0m | \u001b[0m31.96    \u001b[0m | \u001b[0m459.9    \u001b[0m | \u001b[0m415.6    \u001b[0m | \u001b[0m415.6    \u001b[0m | \u001b[0m405.8    \u001b[0m |\n",
      "| \u001b[0m2        \u001b[0m | \u001b[0m0.624    \u001b[0m | \u001b[0m365.2    \u001b[0m | \u001b[0m0.000641 \u001b[0m | \u001b[0m31.24    \u001b[0m | \u001b[0m402.1    \u001b[0m | \u001b[0m497.0    \u001b[0m | \u001b[0m483.2    \u001b[0m | \u001b[0m421.2    \u001b[0m |\n",
      "| \u001b[0m3        \u001b[0m | \u001b[0m0.6216   \u001b[0m | \u001b[0m187.3    \u001b[0m | \u001b[0m0.0002651\u001b[0m | \u001b[0m19.13    \u001b[0m | \u001b[0m452.5    \u001b[0m | \u001b[0m443.2    \u001b[0m | \u001b[0m429.1    \u001b[0m | \u001b[0m461.2    \u001b[0m |\n",
      "| \u001b[95m4        \u001b[0m | \u001b[95m0.6323   \u001b[0m | \u001b[95m176.3    \u001b[0m | \u001b[95m0.0003629\u001b[0m | \u001b[95m20.99    \u001b[0m | \u001b[95m445.6    \u001b[0m | \u001b[95m478.5    \u001b[0m | \u001b[95m420.0    \u001b[0m | \u001b[95m451.4    \u001b[0m |\n",
      "| \u001b[0m5        \u001b[0m | \u001b[0m0.6214   \u001b[0m | \u001b[0m294.0    \u001b[0m | \u001b[0m0.0001418\u001b[0m | \u001b[0m28.23    \u001b[0m | \u001b[0m417.1    \u001b[0m | \u001b[0m406.5    \u001b[0m | \u001b[0m494.9    \u001b[0m | \u001b[0m496.6    \u001b[0m |\n",
      "| \u001b[0m6        \u001b[0m | \u001b[0m0.6254   \u001b[0m | \u001b[0m350.2    \u001b[0m | \u001b[0m0.0003742\u001b[0m | \u001b[0m12.93    \u001b[0m | \u001b[0m468.4    \u001b[0m | \u001b[0m444.0    \u001b[0m | \u001b[0m412.2    \u001b[0m | \u001b[0m449.5    \u001b[0m |\n",
      "| \u001b[0m7        \u001b[0m | \u001b[0m0.6221   \u001b[0m | \u001b[0m148.9    \u001b[0m | \u001b[0m0.0009184\u001b[0m | \u001b[0m17.76    \u001b[0m | \u001b[0m466.3    \u001b[0m | \u001b[0m431.2    \u001b[0m | \u001b[0m452.0    \u001b[0m | \u001b[0m454.7    \u001b[0m |\n",
      "| \u001b[95m8        \u001b[0m | \u001b[95m0.633    \u001b[0m | \u001b[95m188.1    \u001b[0m | \u001b[95m0.0009726\u001b[0m | \u001b[95m33.25    \u001b[0m | \u001b[95m493.9    \u001b[0m | \u001b[95m489.5    \u001b[0m | \u001b[95m459.8    \u001b[0m | \u001b[95m492.2    \u001b[0m |\n",
      "| \u001b[0m9        \u001b[0m | \u001b[0m0.6292   \u001b[0m | \u001b[0m163.0    \u001b[0m | \u001b[0m0.0002764\u001b[0m | \u001b[0m11.36    \u001b[0m | \u001b[0m432.5    \u001b[0m | \u001b[0m438.9    \u001b[0m | \u001b[0m427.1    \u001b[0m | \u001b[0m482.9    \u001b[0m |\n",
      "| \u001b[0m10       \u001b[0m | \u001b[0m0.6294   \u001b[0m | \u001b[0m232.8    \u001b[0m | \u001b[0m0.0003528\u001b[0m | \u001b[0m26.28    \u001b[0m | \u001b[0m414.1    \u001b[0m | \u001b[0m480.2    \u001b[0m | \u001b[0m407.5    \u001b[0m | \u001b[0m498.7    \u001b[0m |\n",
      "| \u001b[0m11       \u001b[0m | \u001b[0m0.613    \u001b[0m | \u001b[0m167.4    \u001b[0m | \u001b[0m0.0001452\u001b[0m | \u001b[0m10.69    \u001b[0m | \u001b[0m443.1    \u001b[0m | \u001b[0m442.7    \u001b[0m | \u001b[0m418.6    \u001b[0m | \u001b[0m478.4    \u001b[0m |\n",
      "| \u001b[95m12       \u001b[0m | \u001b[95m0.6332   \u001b[0m | \u001b[95m156.7    \u001b[0m | \u001b[95m0.0001981\u001b[0m | \u001b[95m36.89    \u001b[0m | \u001b[95m485.0    \u001b[0m | \u001b[95m475.2    \u001b[0m | \u001b[95m427.9    \u001b[0m | \u001b[95m449.8    \u001b[0m |\n",
      "| \u001b[0m13       \u001b[0m | \u001b[0m0.6206   \u001b[0m | \u001b[0m250.7    \u001b[0m | \u001b[0m0.0004067\u001b[0m | \u001b[0m37.15    \u001b[0m | \u001b[0m447.3    \u001b[0m | \u001b[0m494.3    \u001b[0m | \u001b[0m429.7    \u001b[0m | \u001b[0m468.0    \u001b[0m |\n",
      "| \u001b[0m14       \u001b[0m | \u001b[0m0.6249   \u001b[0m | \u001b[0m399.6    \u001b[0m | \u001b[0m0.000146 \u001b[0m | \u001b[0m33.48    \u001b[0m | \u001b[0m474.2    \u001b[0m | \u001b[0m479.2    \u001b[0m | \u001b[0m434.9    \u001b[0m | \u001b[0m446.4    \u001b[0m |\n",
      "| \u001b[0m15       \u001b[0m | \u001b[0m0.6242   \u001b[0m | \u001b[0m284.6    \u001b[0m | \u001b[0m0.0009134\u001b[0m | \u001b[0m29.85    \u001b[0m | \u001b[0m423.1    \u001b[0m | \u001b[0m496.6    \u001b[0m | \u001b[0m439.6    \u001b[0m | \u001b[0m402.8    \u001b[0m |\n",
      "| \u001b[0m16       \u001b[0m | \u001b[0m0.6299   \u001b[0m | \u001b[0m350.4    \u001b[0m | \u001b[0m0.0002735\u001b[0m | \u001b[0m35.52    \u001b[0m | \u001b[0m465.1    \u001b[0m | \u001b[0m466.3    \u001b[0m | \u001b[0m405.1    \u001b[0m | \u001b[0m441.9    \u001b[0m |\n",
      "| \u001b[95m17       \u001b[0m | \u001b[95m0.64     \u001b[0m | \u001b[95m324.5    \u001b[0m | \u001b[95m0.0006683\u001b[0m | \u001b[95m34.05    \u001b[0m | \u001b[95m467.4    \u001b[0m | \u001b[95m484.5    \u001b[0m | \u001b[95m421.6    \u001b[0m | \u001b[95m496.0    \u001b[0m |\n",
      "| \u001b[0m18       \u001b[0m | \u001b[0m0.6207   \u001b[0m | \u001b[0m171.0    \u001b[0m | \u001b[0m0.0009553\u001b[0m | \u001b[0m39.05    \u001b[0m | \u001b[0m495.3    \u001b[0m | \u001b[0m492.5    \u001b[0m | \u001b[0m423.6    \u001b[0m | \u001b[0m442.1    \u001b[0m |\n",
      "| \u001b[0m19       \u001b[0m | \u001b[0m0.6305   \u001b[0m | \u001b[0m393.8    \u001b[0m | \u001b[0m0.0007299\u001b[0m | \u001b[0m37.09    \u001b[0m | \u001b[0m444.5    \u001b[0m | \u001b[0m440.8    \u001b[0m | \u001b[0m424.0    \u001b[0m | \u001b[0m417.9    \u001b[0m |\n",
      "| \u001b[0m20       \u001b[0m | \u001b[0m0.627    \u001b[0m | \u001b[0m251.4    \u001b[0m | \u001b[0m0.0003945\u001b[0m | \u001b[0m25.53    \u001b[0m | \u001b[0m498.1    \u001b[0m | \u001b[0m401.7    \u001b[0m | \u001b[0m489.1    \u001b[0m | \u001b[0m451.9    \u001b[0m |\n",
      "=============================================================================================================\n"
     ]
    }
   ],
   "source": [
    "# re-tuned\n",
    "# Define the search space\n",
    "pbounds = {'units1': (400, 500),\n",
    "           'units2': (400, 500),\n",
    "           'units3': (400, 500),\n",
    "           'units4': (400, 500),\n",
    "           'learning_rate': (1e-4, 1e-3),\n",
    "           'batch_size': (140, 400), #tune batch size\n",
    "           'n_epochs': (10, 40)}\n",
    "\n",
    "# Run the optimization\n",
    "optimizer6 = BayesianOptimization(f=objective_function, pbounds=pbounds, random_state=42)\n",
    "optimizer6.maximize(init_points=10, n_iter=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ffa7e096",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | batch_... | learni... | n_epochs  |  units1   |  units2   |  units3   |  units4   |\n",
      "-------------------------------------------------------------------------------------------------------------\n",
      "| \u001b[0m1        \u001b[0m | \u001b[0m0.5281   \u001b[0m | \u001b[0m46.23    \u001b[0m | \u001b[0m0.009512 \u001b[0m | \u001b[0m20.98    \u001b[0m | \u001b[0m459.9    \u001b[0m | \u001b[0m415.6    \u001b[0m | \u001b[0m415.6    \u001b[0m | \u001b[0m405.8    \u001b[0m |\n",
      "| \u001b[95m2        \u001b[0m | \u001b[95m0.5788   \u001b[0m | \u001b[95m64.91    \u001b[0m | \u001b[95m0.006051 \u001b[0m | \u001b[95m20.62    \u001b[0m | \u001b[95m402.1    \u001b[0m | \u001b[95m497.0    \u001b[0m | \u001b[95m483.2    \u001b[0m | \u001b[95m421.2    \u001b[0m |\n",
      "| \u001b[95m3        \u001b[0m | \u001b[95m0.6127   \u001b[0m | \u001b[95m38.91    \u001b[0m | \u001b[95m0.001916 \u001b[0m | \u001b[95m14.56    \u001b[0m | \u001b[95m452.5    \u001b[0m | \u001b[95m443.2    \u001b[0m | \u001b[95m429.1    \u001b[0m | \u001b[95m461.2    \u001b[0m |\n",
      "| \u001b[0m4        \u001b[0m | \u001b[0m0.5996   \u001b[0m | \u001b[0m37.3     \u001b[0m | \u001b[0m0.002992 \u001b[0m | \u001b[0m15.5     \u001b[0m | \u001b[0m445.6    \u001b[0m | \u001b[0m478.5    \u001b[0m | \u001b[0m420.0    \u001b[0m | \u001b[0m451.4    \u001b[0m |\n",
      "| \u001b[95m5        \u001b[0m | \u001b[95m0.6175   \u001b[0m | \u001b[95m54.51    \u001b[0m | \u001b[95m0.0005599\u001b[0m | \u001b[95m19.11    \u001b[0m | \u001b[95m417.1    \u001b[0m | \u001b[95m406.5    \u001b[0m | \u001b[95m494.9    \u001b[0m | \u001b[95m496.6    \u001b[0m |\n",
      "| \u001b[0m6        \u001b[0m | \u001b[0m0.6039   \u001b[0m | \u001b[0m62.72    \u001b[0m | \u001b[0m0.003116 \u001b[0m | \u001b[0m11.47    \u001b[0m | \u001b[0m468.4    \u001b[0m | \u001b[0m444.0    \u001b[0m | \u001b[0m412.2    \u001b[0m | \u001b[0m449.5    \u001b[0m |\n",
      "| \u001b[0m7        \u001b[0m | \u001b[0m0.5122   \u001b[0m | \u001b[0m33.31    \u001b[0m | \u001b[0m0.009102 \u001b[0m | \u001b[0m13.88    \u001b[0m | \u001b[0m466.3    \u001b[0m | \u001b[0m431.2    \u001b[0m | \u001b[0m452.0    \u001b[0m | \u001b[0m454.7    \u001b[0m |\n",
      "| \u001b[0m8        \u001b[0m | \u001b[0m0.4962   \u001b[0m | \u001b[0m39.02    \u001b[0m | \u001b[0m0.009699 \u001b[0m | \u001b[0m21.63    \u001b[0m | \u001b[0m493.9    \u001b[0m | \u001b[0m489.5    \u001b[0m | \u001b[0m459.8    \u001b[0m | \u001b[0m492.2    \u001b[0m |\n",
      "| \u001b[0m9        \u001b[0m | \u001b[0m0.6146   \u001b[0m | \u001b[0m35.36    \u001b[0m | \u001b[0m0.00204  \u001b[0m | \u001b[0m10.68    \u001b[0m | \u001b[0m432.5    \u001b[0m | \u001b[0m438.9    \u001b[0m | \u001b[0m427.1    \u001b[0m | \u001b[0m482.9    \u001b[0m |\n",
      "| \u001b[0m10       \u001b[0m | \u001b[0m0.5991   \u001b[0m | \u001b[0m45.56    \u001b[0m | \u001b[0m0.002881 \u001b[0m | \u001b[0m18.14    \u001b[0m | \u001b[0m414.1    \u001b[0m | \u001b[0m480.2    \u001b[0m | \u001b[0m407.5    \u001b[0m | \u001b[0m498.7    \u001b[0m |\n",
      "| \u001b[0m11       \u001b[0m | \u001b[0m0.5395   \u001b[0m | \u001b[0m41.89    \u001b[0m | \u001b[0m0.008229 \u001b[0m | \u001b[0m12.97    \u001b[0m | \u001b[0m454.8    \u001b[0m | \u001b[0m444.6    \u001b[0m | \u001b[0m432.6    \u001b[0m | \u001b[0m461.8    \u001b[0m |\n",
      "| \u001b[95m12       \u001b[0m | \u001b[95m0.62     \u001b[0m | \u001b[95m34.45    \u001b[0m | \u001b[95m0.001179 \u001b[0m | \u001b[95m23.45    \u001b[0m | \u001b[95m485.0    \u001b[0m | \u001b[95m475.2    \u001b[0m | \u001b[95m427.9    \u001b[0m | \u001b[95m449.8    \u001b[0m |\n",
      "| \u001b[0m13       \u001b[0m | \u001b[0m0.6106   \u001b[0m | \u001b[0m48.18    \u001b[0m | \u001b[0m0.003474 \u001b[0m | \u001b[0m23.57    \u001b[0m | \u001b[0m447.3    \u001b[0m | \u001b[0m494.3    \u001b[0m | \u001b[0m429.7    \u001b[0m | \u001b[0m468.0    \u001b[0m |\n",
      "| \u001b[95m14       \u001b[0m | \u001b[95m0.6281   \u001b[0m | \u001b[95m69.95    \u001b[0m | \u001b[95m0.0006065\u001b[0m | \u001b[95m21.74    \u001b[0m | \u001b[95m474.2    \u001b[0m | \u001b[95m479.2    \u001b[0m | \u001b[95m434.9    \u001b[0m | \u001b[95m446.4    \u001b[0m |\n",
      "| \u001b[0m15       \u001b[0m | \u001b[0m0.5236   \u001b[0m | \u001b[0m53.13    \u001b[0m | \u001b[0m0.009047 \u001b[0m | \u001b[0m19.93    \u001b[0m | \u001b[0m423.1    \u001b[0m | \u001b[0m496.6    \u001b[0m | \u001b[0m439.6    \u001b[0m | \u001b[0m402.8    \u001b[0m |\n",
      "| \u001b[0m16       \u001b[0m | \u001b[0m0.6175   \u001b[0m | \u001b[0m62.75    \u001b[0m | \u001b[0m0.002008 \u001b[0m | \u001b[0m22.76    \u001b[0m | \u001b[0m465.1    \u001b[0m | \u001b[0m466.3    \u001b[0m | \u001b[0m405.1    \u001b[0m | \u001b[0m441.9    \u001b[0m |\n",
      "| \u001b[0m17       \u001b[0m | \u001b[0m0.581    \u001b[0m | \u001b[0m58.97    \u001b[0m | \u001b[0m0.006352 \u001b[0m | \u001b[0m22.03    \u001b[0m | \u001b[0m467.4    \u001b[0m | \u001b[0m484.5    \u001b[0m | \u001b[0m421.6    \u001b[0m | \u001b[0m496.0    \u001b[0m |\n",
      "| \u001b[0m18       \u001b[0m | \u001b[0m0.502    \u001b[0m | \u001b[0m36.53    \u001b[0m | \u001b[0m0.009508 \u001b[0m | \u001b[0m24.53    \u001b[0m | \u001b[0m495.3    \u001b[0m | \u001b[0m492.5    \u001b[0m | \u001b[0m423.6    \u001b[0m | \u001b[0m442.1    \u001b[0m |\n",
      "| \u001b[0m19       \u001b[0m | \u001b[0m0.5637   \u001b[0m | \u001b[0m69.1     \u001b[0m | \u001b[0m0.007029 \u001b[0m | \u001b[0m23.54    \u001b[0m | \u001b[0m444.5    \u001b[0m | \u001b[0m440.8    \u001b[0m | \u001b[0m424.0    \u001b[0m | \u001b[0m417.9    \u001b[0m |\n",
      "| \u001b[0m20       \u001b[0m | \u001b[0m0.6032   \u001b[0m | \u001b[0m48.28    \u001b[0m | \u001b[0m0.00334  \u001b[0m | \u001b[0m17.76    \u001b[0m | \u001b[0m498.1    \u001b[0m | \u001b[0m401.7    \u001b[0m | \u001b[0m489.1    \u001b[0m | \u001b[0m451.9    \u001b[0m |\n",
      "=============================================================================================================\n"
     ]
    }
   ],
   "source": [
    "# re-tuned\n",
    "# Define the search space\n",
    "pbounds = {'units1': (400, 500),\n",
    "           'units2': (400, 500),\n",
    "           'units3': (400, 500),\n",
    "           'units4': (400, 500),\n",
    "           'learning_rate': (1e-4, 1e-2),\n",
    "           'batch_size': (32, 70), #tune batch size\n",
    "           'n_epochs': (10, 25)}\n",
    "\n",
    "# Run the optimization\n",
    "optimizer6 = BayesianOptimization(f=objective_function, pbounds=pbounds, random_state=42)\n",
    "optimizer6.maximize(init_points=10, n_iter=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf2a1592",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the objective function\n",
    "def objective_function(units1, units2, units3, units4, learning_rate):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=int(units1), activation='relu', input_shape=(324,)))\n",
    "    model.add(Dense(units=int(units2), activation='relu'))\n",
    "    model.add(Dense(units=int(units3), activation='relu'))\n",
    "    model.add(Dense(units=int(units4), activation='relu'))\n",
    "    model.add(Dense(units=10, activation='softmax'))\n",
    "\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    # Define the early stopping callback\n",
    "    early_stop = EarlyStopping(monitor='val_loss', patience=5, verbose=0, restore_best_weights=True)\n",
    "    \n",
    "    history = model.fit(x_train, y_train, verbose=1, validation_data=(x_test, y_test), callbacks=[early_stop])\n",
    "\n",
    "    val_acc = history.history['val_accuracy'][-1]\n",
    "    return val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5576b1a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | learni... |  units1   |  units2   |  units3   |  units4   |\n",
      "-------------------------------------------------------------------------------------\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 1.4418 - accuracy: 0.4854 - val_loss: 1.2575 - val_accuracy: 0.5549\n",
      "| \u001b[0m1        \u001b[0m | \u001b[0m0.5549   \u001b[0m | \u001b[0m0.0004371\u001b[0m | \u001b[0m542.6    \u001b[0m | \u001b[0m509.8    \u001b[0m | \u001b[0m489.8    \u001b[0m | \u001b[0m423.4    \u001b[0m |\n",
      "1563/1563 [==============================] - 43s 27ms/step - loss: 1.4562 - accuracy: 0.4804 - val_loss: 1.2814 - val_accuracy: 0.5518\n",
      "| \u001b[0m2        \u001b[0m | \u001b[0m0.5518   \u001b[0m | \u001b[0m0.0002404\u001b[0m | \u001b[0m408.7    \u001b[0m | \u001b[0m529.9    \u001b[0m | \u001b[0m490.2    \u001b[0m | \u001b[0m506.2    \u001b[0m |\n",
      "1563/1563 [==============================] - 45s 28ms/step - loss: 1.5284 - accuracy: 0.4540 - val_loss: 1.3205 - val_accuracy: 0.5334\n",
      "| \u001b[0m3        \u001b[0m | \u001b[0m0.5334   \u001b[0m | \u001b[0m0.0001185\u001b[0m | \u001b[0m545.5    \u001b[0m | \u001b[0m524.9    \u001b[0m | \u001b[0m431.9    \u001b[0m | \u001b[0m427.3    \u001b[0m |\n",
      "1563/1563 [==============================] - 35s 22ms/step - loss: 1.4571 - accuracy: 0.4796 - val_loss: 1.3031 - val_accuracy: 0.5369\n",
      "| \u001b[0m4        \u001b[0m | \u001b[0m0.5369   \u001b[0m | \u001b[0m0.0002651\u001b[0m | \u001b[0m445.6    \u001b[0m | \u001b[0m478.7    \u001b[0m | \u001b[0m464.8    \u001b[0m | \u001b[0m443.7    \u001b[0m |\n",
      "1563/1563 [==============================] - 37s 23ms/step - loss: 1.4424 - accuracy: 0.4877 - val_loss: 1.2544 - val_accuracy: 0.5597\n",
      "| \u001b[95m5        \u001b[0m | \u001b[95m0.5597   \u001b[0m | \u001b[95m0.0006507\u001b[0m | \u001b[95m420.9    \u001b[0m | \u001b[95m443.8    \u001b[0m | \u001b[95m455.0    \u001b[0m | \u001b[95m468.4    \u001b[0m |\n",
      "1563/1563 [==============================] - 37s 23ms/step - loss: 1.4413 - accuracy: 0.4864 - val_loss: 1.2519 - val_accuracy: 0.5561\n",
      "| \u001b[0m6        \u001b[0m | \u001b[0m0.5561   \u001b[0m | \u001b[0m0.0008067\u001b[0m | \u001b[0m430.0    \u001b[0m | \u001b[0m477.1    \u001b[0m | \u001b[0m488.9    \u001b[0m | \u001b[0m407.0    \u001b[0m |\n",
      "1563/1563 [==============================] - 43s 27ms/step - loss: 1.4382 - accuracy: 0.4883 - val_loss: 1.2822 - val_accuracy: 0.5463\n",
      "| \u001b[0m7        \u001b[0m | \u001b[0m0.5463   \u001b[0m | \u001b[0m0.0006468\u001b[0m | \u001b[0m425.6    \u001b[0m | \u001b[0m409.8    \u001b[0m | \u001b[0m542.3    \u001b[0m | \u001b[0m544.8    \u001b[0m |\n",
      "1563/1563 [==============================] - 42s 26ms/step - loss: 1.4494 - accuracy: 0.4832 - val_loss: 1.2841 - val_accuracy: 0.5490\n",
      "| \u001b[0m8        \u001b[0m | \u001b[0m0.549    \u001b[0m | \u001b[0m0.0008276\u001b[0m | \u001b[0m445.7    \u001b[0m | \u001b[0m414.7    \u001b[0m | \u001b[0m502.6    \u001b[0m | \u001b[0m466.0    \u001b[0m |\n",
      "1563/1563 [==============================] - 38s 24ms/step - loss: 1.4702 - accuracy: 0.4771 - val_loss: 1.2846 - val_accuracy: 0.5463\n",
      "| \u001b[0m9        \u001b[0m | \u001b[0m0.5463   \u001b[0m | \u001b[0m0.0002098\u001b[0m | \u001b[0m474.3    \u001b[0m | \u001b[0m405.2    \u001b[0m | \u001b[0m536.4    \u001b[0m | \u001b[0m438.8    \u001b[0m |\n",
      "1563/1563 [==============================] - 45s 28ms/step - loss: 1.4443 - accuracy: 0.4858 - val_loss: 1.3278 - val_accuracy: 0.5403\n",
      "| \u001b[0m10       \u001b[0m | \u001b[0m0.5403   \u001b[0m | \u001b[0m0.0006963\u001b[0m | \u001b[0m446.8    \u001b[0m | \u001b[0m478.0    \u001b[0m | \u001b[0m482.0    \u001b[0m | \u001b[0m427.7    \u001b[0m |\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 1.4444 - accuracy: 0.4830 - val_loss: 1.2462 - val_accuracy: 0.5608\n",
      "| \u001b[95m11       \u001b[0m | \u001b[95m0.5608   \u001b[0m | \u001b[95m0.0006928\u001b[0m | \u001b[95m411.3    \u001b[0m | \u001b[95m444.1    \u001b[0m | \u001b[95m454.9    \u001b[0m | \u001b[95m477.8    \u001b[0m |\n",
      "1563/1563 [==============================] - 47s 29ms/step - loss: 1.4425 - accuracy: 0.4864 - val_loss: 1.2879 - val_accuracy: 0.5485\n",
      "| \u001b[0m12       \u001b[0m | \u001b[0m0.5485   \u001b[0m | \u001b[0m0.000838 \u001b[0m | \u001b[0m430.9    \u001b[0m | \u001b[0m481.2    \u001b[0m | \u001b[0m492.1    \u001b[0m | \u001b[0m411.1    \u001b[0m |\n",
      "1563/1563 [==============================] - 53s 33ms/step - loss: 1.4394 - accuracy: 0.4886 - val_loss: 1.2650 - val_accuracy: 0.5557\n",
      "| \u001b[0m13       \u001b[0m | \u001b[0m0.5557   \u001b[0m | \u001b[0m0.0006256\u001b[0m | \u001b[0m407.2    \u001b[0m | \u001b[0m405.4    \u001b[0m | \u001b[0m415.7    \u001b[0m | \u001b[0m435.0    \u001b[0m |\n",
      "1563/1563 [==============================] - 42s 27ms/step - loss: 1.4373 - accuracy: 0.4880 - val_loss: 1.2511 - val_accuracy: 0.5653\n",
      "| \u001b[95m14       \u001b[0m | \u001b[95m0.5653   \u001b[0m | \u001b[95m0.0005217\u001b[0m | \u001b[95m549.0    \u001b[0m | \u001b[95m538.3    \u001b[0m | \u001b[95m464.8    \u001b[0m | \u001b[95m447.3    \u001b[0m |\n",
      "1563/1563 [==============================] - 49s 31ms/step - loss: 1.4486 - accuracy: 0.4839 - val_loss: 1.2741 - val_accuracy: 0.5497\n",
      "| \u001b[0m15       \u001b[0m | \u001b[0m0.5497   \u001b[0m | \u001b[0m0.0008268\u001b[0m | \u001b[0m426.4    \u001b[0m | \u001b[0m447.5    \u001b[0m | \u001b[0m440.3    \u001b[0m | \u001b[0m508.9    \u001b[0m |\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 1.4300 - accuracy: 0.4881 - val_loss: 1.2665 - val_accuracy: 0.5561\n",
      "| \u001b[0m16       \u001b[0m | \u001b[0m0.5561   \u001b[0m | \u001b[0m0.0005421\u001b[0m | \u001b[0m438.4    \u001b[0m | \u001b[0m510.3    \u001b[0m | \u001b[0m489.4    \u001b[0m | \u001b[0m519.7    \u001b[0m |\n",
      "1563/1563 [==============================] - 38s 24ms/step - loss: 1.4883 - accuracy: 0.4707 - val_loss: 1.3037 - val_accuracy: 0.5406\n",
      "| \u001b[0m17       \u001b[0m | \u001b[0m0.5406   \u001b[0m | \u001b[0m0.0001679\u001b[0m | \u001b[0m521.8    \u001b[0m | \u001b[0m470.0    \u001b[0m | \u001b[0m445.9    \u001b[0m | \u001b[0m444.8    \u001b[0m |\n",
      "1563/1563 [==============================] - 40s 25ms/step - loss: 1.4996 - accuracy: 0.4662 - val_loss: 1.3278 - val_accuracy: 0.5259\n",
      "| \u001b[0m18       \u001b[0m | \u001b[0m0.5259   \u001b[0m | \u001b[0m0.0001419\u001b[0m | \u001b[0m545.3    \u001b[0m | \u001b[0m546.7    \u001b[0m | \u001b[0m476.4    \u001b[0m | \u001b[0m447.4    \u001b[0m |\n",
      "1563/1563 [==============================] - 40s 25ms/step - loss: 1.4433 - accuracy: 0.4853 - val_loss: 1.2610 - val_accuracy: 0.5563\n",
      "| \u001b[0m19       \u001b[0m | \u001b[0m0.5563   \u001b[0m | \u001b[0m0.0007553\u001b[0m | \u001b[0m500.1    \u001b[0m | \u001b[0m549.2    \u001b[0m | \u001b[0m461.0    \u001b[0m | \u001b[0m480.8    \u001b[0m |\n",
      "1563/1563 [==============================] - 48s 30ms/step - loss: 1.4736 - accuracy: 0.4757 - val_loss: 1.3086 - val_accuracy: 0.5395\n",
      "| \u001b[0m20       \u001b[0m | \u001b[0m0.5395   \u001b[0m | \u001b[0m0.0002202\u001b[0m | \u001b[0m510.6    \u001b[0m | \u001b[0m445.2    \u001b[0m | \u001b[0m428.4    \u001b[0m | \u001b[0m434.0    \u001b[0m |\n",
      "=====================================================================================\n"
     ]
    }
   ],
   "source": [
    "# re-tuned\n",
    "# Define the search space\n",
    "pbounds = {'units1': (400, 550),\n",
    "           'units2': (400, 550),\n",
    "           'units3': (400, 550),\n",
    "           'units4': (400, 550),\n",
    "           'learning_rate': (1e-4, 1e-3)}\n",
    "\n",
    "# Run the optimization\n",
    "optimizer6 = BayesianOptimization(f=objective_function, pbounds=pbounds, random_state=42)\n",
    "optimizer6.maximize(init_points=10, n_iter=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67608b28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | learni... |  units1   |  units2   |  units3   |  units4   |\n",
      "-------------------------------------------------------------------------------------\n",
      "| \u001b[0m1        \u001b[0m | \u001b[0m0.5172   \u001b[0m | \u001b[0m0.003808 \u001b[0m | \u001b[0m488.3    \u001b[0m | \u001b[0m383.4    \u001b[0m | \u001b[0m319.4    \u001b[0m | \u001b[0m106.9    \u001b[0m |\n",
      "| \u001b[95m2        \u001b[0m | \u001b[95m0.5176   \u001b[0m | \u001b[95m0.001644 \u001b[0m | \u001b[95m59.88    \u001b[0m | \u001b[95m447.8    \u001b[0m | \u001b[95m320.5    \u001b[0m | \u001b[95m371.9    \u001b[0m |\n",
      "| \u001b[95m3        \u001b[0m | \u001b[95m0.5401   \u001b[0m | \u001b[95m0.0003038\u001b[0m | \u001b[95m497.6    \u001b[0m | \u001b[95m431.6    \u001b[0m | \u001b[95m133.9    \u001b[0m | \u001b[95m119.3    \u001b[0m |\n",
      "| \u001b[0m4        \u001b[0m | \u001b[0m0.5294   \u001b[0m | \u001b[0m0.001916 \u001b[0m | \u001b[0m178.0    \u001b[0m | \u001b[0m283.9    \u001b[0m | \u001b[0m239.3    \u001b[0m | \u001b[0m171.8    \u001b[0m |\n",
      "| \u001b[0m5        \u001b[0m | \u001b[0m0.4894   \u001b[0m | \u001b[0m0.006157 \u001b[0m | \u001b[0m98.96    \u001b[0m | \u001b[0m172.2    \u001b[0m | \u001b[0m207.9    \u001b[0m | \u001b[0m250.9    \u001b[0m |\n",
      "| \u001b[0m6        \u001b[0m | \u001b[0m0.4584   \u001b[0m | \u001b[0m0.007873 \u001b[0m | \u001b[0m127.8    \u001b[0m | \u001b[0m278.8    \u001b[0m | \u001b[0m316.4    \u001b[0m | \u001b[0m54.3     \u001b[0m |\n",
      "| \u001b[0m7        \u001b[0m | \u001b[0m0.4741   \u001b[0m | \u001b[0m0.006115 \u001b[0m | \u001b[0m113.9    \u001b[0m | \u001b[0m63.22    \u001b[0m | \u001b[0m487.5    \u001b[0m | \u001b[0m495.5    \u001b[0m |\n",
      "| \u001b[0m8        \u001b[0m | \u001b[0m0.4588   \u001b[0m | \u001b[0m0.008103 \u001b[0m | \u001b[0m178.2    \u001b[0m | \u001b[0m78.88    \u001b[0m | \u001b[0m360.4    \u001b[0m | \u001b[0m243.3    \u001b[0m |\n",
      "| \u001b[0m9        \u001b[0m | \u001b[0m0.5271   \u001b[0m | \u001b[0m0.001308 \u001b[0m | \u001b[0m269.7    \u001b[0m | \u001b[0m48.51    \u001b[0m | \u001b[0m468.5    \u001b[0m | \u001b[0m156.2    \u001b[0m |\n",
      "| \u001b[0m10       \u001b[0m | \u001b[0m0.4957   \u001b[0m | \u001b[0m0.006659 \u001b[0m | \u001b[0m181.6    \u001b[0m | \u001b[0m281.6    \u001b[0m | \u001b[0m294.4    \u001b[0m | \u001b[0m120.7    \u001b[0m |\n",
      "| \u001b[0m11       \u001b[0m | \u001b[0m0.5031   \u001b[0m | \u001b[0m0.003932 \u001b[0m | \u001b[0m363.7    \u001b[0m | \u001b[0m155.9    \u001b[0m | \u001b[0m431.4    \u001b[0m | \u001b[0m324.7    \u001b[0m |\n",
      "| \u001b[0m12       \u001b[0m | \u001b[0m0.4113   \u001b[0m | \u001b[0m0.009073 \u001b[0m | \u001b[0m82.57    \u001b[0m | \u001b[0m102.7    \u001b[0m | \u001b[0m476.1    \u001b[0m | \u001b[0m401.9    \u001b[0m |\n",
      "| \u001b[0m13       \u001b[0m | \u001b[0m0.4861   \u001b[0m | \u001b[0m0.005882 \u001b[0m | \u001b[0m54.94    \u001b[0m | \u001b[0m49.19    \u001b[0m | \u001b[0m82.17    \u001b[0m | \u001b[0m143.9    \u001b[0m |\n",
      "| \u001b[0m14       \u001b[0m | \u001b[0m0.462    \u001b[0m | \u001b[0m0.008669 \u001b[0m | \u001b[0m420.3    \u001b[0m | \u001b[0m403.6    \u001b[0m | \u001b[0m204.3    \u001b[0m | \u001b[0m117.1    \u001b[0m |\n",
      "| \u001b[0m15       \u001b[0m | \u001b[0m0.4265   \u001b[0m | \u001b[0m0.008095 \u001b[0m | \u001b[0m116.4    \u001b[0m | \u001b[0m184.0    \u001b[0m | \u001b[0m161.1    \u001b[0m | \u001b[0m380.4    \u001b[0m |\n",
      "| \u001b[0m16       \u001b[0m | \u001b[0m0.4686   \u001b[0m | \u001b[0m0.004964 \u001b[0m | \u001b[0m154.7    \u001b[0m | \u001b[0m384.9    \u001b[0m | \u001b[0m318.0    \u001b[0m | \u001b[0m415.1    \u001b[0m |\n",
      "| \u001b[0m17       \u001b[0m | \u001b[0m0.5341   \u001b[0m | \u001b[0m0.0004593\u001b[0m | \u001b[0m507.4    \u001b[0m | \u001b[0m409.5    \u001b[0m | \u001b[0m112.6    \u001b[0m | \u001b[0m115.3    \u001b[0m |\n",
      "| \u001b[0m18       \u001b[0m | \u001b[0m0.4765   \u001b[0m | \u001b[0m0.007527 \u001b[0m | \u001b[0m495.8    \u001b[0m | \u001b[0m418.8    \u001b[0m | \u001b[0m106.3    \u001b[0m | \u001b[0m118.2    \u001b[0m |\n",
      "| \u001b[0m19       \u001b[0m | \u001b[0m0.4388   \u001b[0m | \u001b[0m0.007309 \u001b[0m | \u001b[0m352.4    \u001b[0m | \u001b[0m509.4    \u001b[0m | \u001b[0m227.2    \u001b[0m | \u001b[0m290.6    \u001b[0m |\n",
      "| \u001b[95m20       \u001b[0m | \u001b[95m0.5499   \u001b[0m | \u001b[95m0.001423 \u001b[0m | \u001b[95m385.9    \u001b[0m | \u001b[95m176.6    \u001b[0m | \u001b[95m123.0    \u001b[0m | \u001b[95m140.9    \u001b[0m |\n",
      "| \u001b[0m21       \u001b[0m | \u001b[0m0.5074   \u001b[0m | \u001b[0m0.002787 \u001b[0m | \u001b[0m344.8    \u001b[0m | \u001b[0m61.84    \u001b[0m | \u001b[0m390.6    \u001b[0m | \u001b[0m492.4    \u001b[0m |\n",
      "| \u001b[0m22       \u001b[0m | \u001b[0m0.5207   \u001b[0m | \u001b[0m0.001722 \u001b[0m | \u001b[0m80.53    \u001b[0m | \u001b[0m146.2    \u001b[0m | \u001b[0m469.9    \u001b[0m | \u001b[0m413.7    \u001b[0m |\n",
      "| \u001b[0m23       \u001b[0m | \u001b[0m0.4298   \u001b[0m | \u001b[0m0.007797 \u001b[0m | \u001b[0m203.6    \u001b[0m | \u001b[0m434.1    \u001b[0m | \u001b[0m480.6    \u001b[0m | \u001b[0m110.3    \u001b[0m |\n",
      "| \u001b[0m24       \u001b[0m | \u001b[0m0.4802   \u001b[0m | \u001b[0m0.005106 \u001b[0m | \u001b[0m277.6    \u001b[0m | \u001b[0m411.9    \u001b[0m | \u001b[0m190.6    \u001b[0m | \u001b[0m474.8    \u001b[0m |\n",
      "| \u001b[0m25       \u001b[0m | \u001b[0m0.434    \u001b[0m | \u001b[0m0.008652 \u001b[0m | \u001b[0m306.6    \u001b[0m | \u001b[0m231.8    \u001b[0m | \u001b[0m120.0    \u001b[0m | \u001b[0m167.1    \u001b[0m |\n",
      "| \u001b[0m26       \u001b[0m | \u001b[0m0.4893   \u001b[0m | \u001b[0m0.006286 \u001b[0m | \u001b[0m398.3    \u001b[0m | \u001b[0m216.1    \u001b[0m | \u001b[0m123.2    \u001b[0m | \u001b[0m434.0    \u001b[0m |\n",
      "| \u001b[0m27       \u001b[0m | \u001b[0m0.4836   \u001b[0m | \u001b[0m0.005705 \u001b[0m | \u001b[0m57.04    \u001b[0m | \u001b[0m206.8    \u001b[0m | \u001b[0m110.4    \u001b[0m | \u001b[0m106.4    \u001b[0m |\n",
      "| \u001b[0m28       \u001b[0m | \u001b[0m0.4741   \u001b[0m | \u001b[0m0.005407 \u001b[0m | \u001b[0m416.8    \u001b[0m | \u001b[0m428.5    \u001b[0m | \u001b[0m295.7    \u001b[0m | \u001b[0m294.2    \u001b[0m |\n",
      "| \u001b[0m29       \u001b[0m | \u001b[0m0.5088   \u001b[0m | \u001b[0m0.0007795\u001b[0m | \u001b[0m65.23    \u001b[0m | \u001b[0m105.6    \u001b[0m | \u001b[0m194.3    \u001b[0m | \u001b[0m211.1    \u001b[0m |\n",
      "| \u001b[0m30       \u001b[0m | \u001b[0m0.4905   \u001b[0m | \u001b[0m0.004421 \u001b[0m | \u001b[0m104.5    \u001b[0m | \u001b[0m309.5    \u001b[0m | \u001b[0m379.9    \u001b[0m | \u001b[0m97.22    \u001b[0m |\n",
      "| \u001b[0m31       \u001b[0m | \u001b[0m0.5134   \u001b[0m | \u001b[0m0.002435 \u001b[0m | \u001b[0m331.6    \u001b[0m | \u001b[0m440.2    \u001b[0m | \u001b[0m440.9    \u001b[0m | \u001b[0m421.2    \u001b[0m |\n",
      "| \u001b[0m32       \u001b[0m | \u001b[0m0.4904   \u001b[0m | \u001b[0m0.004373 \u001b[0m | \u001b[0m432.8    \u001b[0m | \u001b[0m333.9    \u001b[0m | \u001b[0m94.41    \u001b[0m | \u001b[0m45.81    \u001b[0m |\n",
      "| \u001b[0m33       \u001b[0m | \u001b[0m0.4646   \u001b[0m | \u001b[0m0.009843 \u001b[0m | \u001b[0m211.9    \u001b[0m | \u001b[0m131.0    \u001b[0m | \u001b[0m389.1    \u001b[0m | \u001b[0m355.8    \u001b[0m |\n",
      "| \u001b[0m34       \u001b[0m | \u001b[0m0.4512   \u001b[0m | \u001b[0m0.008869 \u001b[0m | \u001b[0m188.4    \u001b[0m | \u001b[0m281.6    \u001b[0m | \u001b[0m297.8    \u001b[0m | \u001b[0m115.4    \u001b[0m |\n",
      "| \u001b[0m35       \u001b[0m | \u001b[0m0.4812   \u001b[0m | \u001b[0m0.004688 \u001b[0m | \u001b[0m397.4    \u001b[0m | \u001b[0m381.9    \u001b[0m | \u001b[0m465.0    \u001b[0m | \u001b[0m82.39    \u001b[0m |\n",
      "| \u001b[0m36       \u001b[0m | \u001b[0m0.5168   \u001b[0m | \u001b[0m0.002956 \u001b[0m | \u001b[0m498.3    \u001b[0m | \u001b[0m126.8    \u001b[0m | \u001b[0m492.2    \u001b[0m | \u001b[0m500.6    \u001b[0m |\n",
      "| \u001b[0m37       \u001b[0m | \u001b[0m0.4419   \u001b[0m | \u001b[0m0.007771 \u001b[0m | \u001b[0m36.94    \u001b[0m | \u001b[0m136.9    \u001b[0m | \u001b[0m275.7    \u001b[0m | \u001b[0m208.3    \u001b[0m |\n",
      "| \u001b[0m38       \u001b[0m | \u001b[0m0.4084   \u001b[0m | \u001b[0m0.006291 \u001b[0m | \u001b[0m45.37    \u001b[0m | \u001b[0m282.6    \u001b[0m | \u001b[0m325.1    \u001b[0m | \u001b[0m511.1    \u001b[0m |\n",
      "| \u001b[0m39       \u001b[0m | \u001b[0m0.4603   \u001b[0m | \u001b[0m0.00545  \u001b[0m | \u001b[0m88.07    \u001b[0m | \u001b[0m224.4    \u001b[0m | \u001b[0m351.3    \u001b[0m | \u001b[0m318.3    \u001b[0m |\n",
      "| \u001b[0m40       \u001b[0m | \u001b[0m0.4546   \u001b[0m | \u001b[0m0.007972 \u001b[0m | \u001b[0m259.2    \u001b[0m | \u001b[0m172.9    \u001b[0m | \u001b[0m373.2    \u001b[0m | \u001b[0m511.0    \u001b[0m |\n",
      "| \u001b[0m41       \u001b[0m | \u001b[0m0.4683   \u001b[0m | \u001b[0m0.005987 \u001b[0m | \u001b[0m95.17    \u001b[0m | \u001b[0m428.0    \u001b[0m | \u001b[0m151.9    \u001b[0m | \u001b[0m132.4    \u001b[0m |\n",
      "| \u001b[0m42       \u001b[0m | \u001b[0m0.5149   \u001b[0m | \u001b[0m0.003468 \u001b[0m | \u001b[0m442.2    \u001b[0m | \u001b[0m71.12    \u001b[0m | \u001b[0m234.5    \u001b[0m | \u001b[0m126.9    \u001b[0m |\n",
      "| \u001b[0m43       \u001b[0m | \u001b[0m0.4927   \u001b[0m | \u001b[0m0.004365 \u001b[0m | \u001b[0m370.1    \u001b[0m | \u001b[0m465.3    \u001b[0m | \u001b[0m329.9    \u001b[0m | \u001b[0m65.73    \u001b[0m |\n",
      "| \u001b[0m44       \u001b[0m | \u001b[0m0.5184   \u001b[0m | \u001b[0m0.002749 \u001b[0m | \u001b[0m230.6    \u001b[0m | \u001b[0m63.14    \u001b[0m | \u001b[0m403.8    \u001b[0m | \u001b[0m41.15    \u001b[0m |\n",
      "| \u001b[0m45       \u001b[0m | \u001b[0m0.5084   \u001b[0m | \u001b[0m0.00292  \u001b[0m | \u001b[0m55.39    \u001b[0m | \u001b[0m77.81    \u001b[0m | \u001b[0m463.3    \u001b[0m | \u001b[0m499.4    \u001b[0m |\n",
      "| \u001b[0m46       \u001b[0m | \u001b[0m0.5004   \u001b[0m | \u001b[0m0.002832 \u001b[0m | \u001b[0m94.53    \u001b[0m | \u001b[0m243.2    \u001b[0m | \u001b[0m248.5    \u001b[0m | \u001b[0m416.1    \u001b[0m |\n",
      "| \u001b[0m47       \u001b[0m | \u001b[0m0.4391   \u001b[0m | \u001b[0m0.009811 \u001b[0m | \u001b[0m90.6     \u001b[0m | \u001b[0m196.1    \u001b[0m | \u001b[0m34.12    \u001b[0m | \u001b[0m188.4    \u001b[0m |\n",
      "| \u001b[0m48       \u001b[0m | \u001b[0m0.4958   \u001b[0m | \u001b[0m0.005126 \u001b[0m | \u001b[0m345.3    \u001b[0m | \u001b[0m165.8    \u001b[0m | \u001b[0m449.9    \u001b[0m | \u001b[0m272.4    \u001b[0m |\n",
      "| \u001b[0m49       \u001b[0m | \u001b[0m0.4985   \u001b[0m | \u001b[0m0.002883 \u001b[0m | \u001b[0m451.6    \u001b[0m | \u001b[0m286.9    \u001b[0m | \u001b[0m269.2    \u001b[0m | \u001b[0m492.4    \u001b[0m |\n",
      "| \u001b[0m50       \u001b[0m | \u001b[0m0.4815   \u001b[0m | \u001b[0m0.005143 \u001b[0m | \u001b[0m150.5    \u001b[0m | \u001b[0m140.9    \u001b[0m | \u001b[0m267.2    \u001b[0m | \u001b[0m267.8    \u001b[0m |\n",
      "| \u001b[0m51       \u001b[0m | \u001b[0m0.5445   \u001b[0m | \u001b[0m0.000961 \u001b[0m | \u001b[0m455.0    \u001b[0m | \u001b[0m430.1    \u001b[0m | \u001b[0m483.4    \u001b[0m | \u001b[0m275.4    \u001b[0m |\n",
      "| \u001b[0m52       \u001b[0m | \u001b[0m0.4225   \u001b[0m | \u001b[0m0.008447 \u001b[0m | \u001b[0m434.2    \u001b[0m | \u001b[0m46.32    \u001b[0m | \u001b[0m389.4    \u001b[0m | \u001b[0m374.3    \u001b[0m |\n",
      "| \u001b[0m53       \u001b[0m | \u001b[0m0.5392   \u001b[0m | \u001b[0m0.001556 \u001b[0m | \u001b[0m320.8    \u001b[0m | \u001b[0m444.9    \u001b[0m | \u001b[0m362.3    \u001b[0m | \u001b[0m464.7    \u001b[0m |\n",
      "| \u001b[0m54       \u001b[0m | \u001b[0m0.4904   \u001b[0m | \u001b[0m0.005573 \u001b[0m | \u001b[0m351.2    \u001b[0m | \u001b[0m138.5    \u001b[0m | \u001b[0m276.3    \u001b[0m | \u001b[0m52.99    \u001b[0m |\n",
      "| \u001b[0m55       \u001b[0m | \u001b[0m0.4866   \u001b[0m | \u001b[0m0.004818 \u001b[0m | \u001b[0m400.2    \u001b[0m | \u001b[0m113.4    \u001b[0m | \u001b[0m420.9    \u001b[0m | \u001b[0m309.8    \u001b[0m |\n",
      "| \u001b[0m56       \u001b[0m | \u001b[0m0.5262   \u001b[0m | \u001b[0m0.001178 \u001b[0m | \u001b[0m159.9    \u001b[0m | \u001b[0m122.5    \u001b[0m | \u001b[0m259.3    \u001b[0m | \u001b[0m93.49    \u001b[0m |\n",
      "| \u001b[0m57       \u001b[0m | \u001b[0m0.4297   \u001b[0m | \u001b[0m0.009136 \u001b[0m | \u001b[0m230.1    \u001b[0m | \u001b[0m246.3    \u001b[0m | \u001b[0m363.8    \u001b[0m | \u001b[0m465.2    \u001b[0m |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m58       \u001b[0m | \u001b[0m0.4518   \u001b[0m | \u001b[0m0.009723 \u001b[0m | \u001b[0m260.6    \u001b[0m | \u001b[0m498.3    \u001b[0m | \u001b[0m244.6    \u001b[0m | \u001b[0m271.2    \u001b[0m |\n",
      "| \u001b[0m59       \u001b[0m | \u001b[0m0.4824   \u001b[0m | \u001b[0m0.005699 \u001b[0m | \u001b[0m146.7    \u001b[0m | \u001b[0m83.6     \u001b[0m | \u001b[0m438.2    \u001b[0m | \u001b[0m490.4    \u001b[0m |\n",
      "| \u001b[95m60       \u001b[0m | \u001b[95m0.5578   \u001b[0m | \u001b[95m0.0008001\u001b[0m | \u001b[95m394.5    \u001b[0m | \u001b[95m240.8    \u001b[0m | \u001b[95m207.6    \u001b[0m | \u001b[95m470.0    \u001b[0m |\n",
      "=====================================================================================\n"
     ]
    }
   ],
   "source": [
    "# re-tuned\n",
    "# Define the search space\n",
    "pbounds = {'units1': (32, 512),\n",
    "           'units2': (32, 512),\n",
    "           'units3': (32, 512),\n",
    "           'units4': (32, 512),\n",
    "           'learning_rate': (1e-4, 1e-2)}\n",
    "\n",
    "# Run the optimization\n",
    "optimizer6 = BayesianOptimization(f=objective_function, pbounds=pbounds, random_state=42)\n",
    "optimizer6.maximize(init_points=10, n_iter=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1dfdb89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batch_size': 266.0927003345415,\n",
       " 'learning_rate': 0.001098609322769119,\n",
       " 'n_epochs': 46.892362254235735,\n",
       " 'units1': 434.9946745178665,\n",
       " 'units2': 357.8159679372243,\n",
       " 'units3': 45.57874587181616,\n",
       " 'units4': 64.93450859931866}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Best_hyperparameters= {'batch_size': 266.0927003345415, 'learning_rate': 0.001098609322769119, 'n_epochs': 46.892362254235735, 'units1': 434.9946745178665, 'units2': 357.8159679372243, 'units3': 45.57874587181616, 'units4': 64.93450859931866}\n",
    "Best_hyperparameters"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 832.707164,
   "end_time": "2022-09-22T15:48:44.294696",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-09-22T15:34:51.587532",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
